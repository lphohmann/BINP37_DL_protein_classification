{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2D_ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RNOs9h03HA0w",
        "x0xWfZtSrWj2",
        "aZ3rltkKJRMO",
        "QWIj7EZZnGWJ"
      ],
      "authorship_tag": "ABX9TyN7hBAhNGbuJtZZ6vRjv9iV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lphohmann/DL_microbial_gene_classifier/blob/main/2D_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wz-gDZbrlar"
      },
      "source": [
        "To do:\n",
        "- add 1 initital layer to increase from 1 to 3 channels or change input data to 3 channels\n",
        "- solve error arising due to datalaoders changing tensor typre by casting the input to float type by doing\n",
        "input=input.float() before calling the forward pass. Alt. idea: use model hook or callback that is executed before the forward pass?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNOs9h03HA0w"
      },
      "source": [
        "# Setting everything up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQFnDp2fo-H_"
      },
      "source": [
        "%%capture\n",
        "!pip install fastai --upgrade\n",
        "#!pip install -Uqq fastbook --upgrade\n",
        "#!pip install torchtext==0.8.1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E-3B33Y5x84"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT3j2jdYk2gy"
      },
      "source": [
        "#hide\n",
        "#import fastbook\n",
        "#fastbook.setup_book()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFzbFyx1k3Q7"
      },
      "source": [
        "#hide\n",
        "#import fastai\n",
        "from fastai import *\n",
        "from fastai.vision.all import *\n",
        "#from fastai.text.all import *\n",
        "#from fastai.callback import *"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pvbcIQBeiBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c0a7a6-fd1d-469b-d57c-51903f6a3a73"
      },
      "source": [
        "# mount google drive to access files and set the correct working\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd drive/MyDrive/ColabNotebooks/DL_project/\n",
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ColabNotebooks/DL_project\n",
            "/content/drive/MyDrive/ColabNotebooks/DL_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0xWfZtSrWj2"
      },
      "source": [
        "# Define functions required for creating the Datablock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxYlGka0tODh"
      },
      "source": [
        "# get the training and validation datasets"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Guo00Z6aDNiE"
      },
      "source": [
        "# defining functions required for building the DataBlock\n",
        "# one hot encoding function\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def OH_enc(seq: str):\n",
        "    # get the categories into array\n",
        "    cats = ['K', 'D', 'N', 'E', 'R', 'A', 'T', 'L', 'I', 'Q', 'C', 'F', 'G', 'W', 'M', 'S', 'H', 'P', 'V', 'Y']\n",
        "    cat_array = np.array(sorted(cats), ndmin=1) #\n",
        "    # get seq into array\n",
        "    trunc_seq = seq[:300] # truncate sequences longer than 300 \n",
        "    seq_array = np.array(list(trunc_seq))\n",
        "    #one hot encode the sequence\n",
        "    onehot_encoder = OneHotEncoder(categories=[cat_array],sparse=False,handle_unknown='ignore')\n",
        "    onehot_encoded_seq = onehot_encoder.fit_transform(seq_array.reshape(len(seq_array), 1))\n",
        "    return np.transpose(onehot_encoded_seq)\n",
        "\n",
        "# zero padding function\n",
        "def pad_along_axis(array: np.ndarray, target_length: int, axis: int = 0):\n",
        "    pad_size = target_length - array.shape[axis]\n",
        "    if pad_size <= 0:\n",
        "        return array\n",
        "    npad = [(0, 0)] * array.ndim\n",
        "    npad[axis] = (0, pad_size)\n",
        "    return np.pad(array, pad_width=npad, mode='constant', constant_values=0)\n",
        "\n",
        "# combine in one function\n",
        "def main_item_tfms(seq): # added -> None because the tensor shape later is 1,2820 and i think it should be 20,2820\n",
        "    enc_seq = OH_enc(seq)\n",
        "    pad_encseq_array = pad_along_axis(enc_seq,300,1)\n",
        "    return pad_encseq_array "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpO8YNjp4SUv"
      },
      "source": [
        "# get_x and y by specifying column in dataframe\n",
        "def get_y(r): return r['Knum']\n",
        "def get_x(r): \n",
        "    #return np.expand_dims(main_item_tfms(r['Seq']),0) # apply the one hot encoding + padding function and add a dimension at 0 leading to shape ([256, 1, 20, 300])\n",
        "    return np.broadcast_to(np.expand_dims(main_item_tfms(r['Seq']),0), (3, 20, 300)).copy() # apply the one hot encoding + padding function and add a 3 dimensions at 0 leading to shape ([256, 3, 20, 300])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC97n5teDZiG"
      },
      "source": [
        "# read in my data from which training and validation set will be created\n",
        "trainval = pd.read_csv('trainval.csv', low_memory=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwCPlBdOznAz"
      },
      "source": [
        "# CategoryBlock -> typetfm: categorize, batchtfm: CUDA, itemtfm: totensor\n",
        "def CategoryBlock(vocab=None, sort=True, add_na=False):\n",
        "    \"`TransformBlock` for single-label categorical targets\"\n",
        "    return TransformBlock(type_tfms=Categorize(vocab=vocab, sort=sort, add_na=add_na))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvFA5HinvFns"
      },
      "source": [
        "# alternative DataBlock try\n",
        "# building the datablock\n",
        "dblock = DataBlock(blocks=(TransformBlock(batch_tfms=IntToFloatTensor), CategoryBlock(vocab=['K00024', 'K00121', 'K00122', 'K00123', 'K00124', 'K00126',\n",
        "       'K00127', 'K00148', 'K00169', 'K00170', 'K00171', 'K00172',\n",
        "       'K00194', 'K00196', 'K00197', 'K00198', 'K00200', 'K00201',\n",
        "       'K00202', 'K00317', 'K00320', 'K00441', 'K00600', 'K00625',\n",
        "       'K00672', 'K00830', 'K00925', 'K01007', 'K01070', 'K01499',\n",
        "       'K01595', 'K01895', 'K03388', 'K03389', 'K03390', 'K05979',\n",
        "       'K06034', 'K08097', 'K08691', 'K08692', 'K09733', 'K10713',\n",
        "       'K10714', 'K11212', 'K11261', 'K11779', 'K11780', 'K12234',\n",
        "       'K13039', 'K13788', 'K14067', 'K14080', 'K14083', 'K14940',\n",
        "       'K14941', 'K15228', 'K15229', 'K18277'])),\n",
        "                 splitter = TrainTestSplitter(test_size=0.2, random_state=42, stratify=trainval[['Knum']]),\n",
        "                 get_x = get_x,\n",
        "                 get_y = get_y\n",
        "                 )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUxNCw2kvrsq"
      },
      "source": [
        "#dblock.summary(trainval)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ3rltkKJRMO"
      },
      "source": [
        "# Create the dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz27HTxgLIBi"
      },
      "source": [
        "# create dataloaders from datablock \n",
        "dls = dblock.dataloaders(trainval, bs=256, shuffle=True, drop_last=True) # shuffle the data to prevent overfitting due to an organized dataset and drop the last incomplete batch"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yA2Jp-0afhb"
      },
      "source": [
        "# visualize batch label distribution, compare with hist after balance correction\n",
        "x,y = dls.one_batch()\n",
        "import matplotlib.pyplot as plt\n",
        "#plt.hist(y,bins=dls.c) # if run with gpu there is a type error"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lefVyPCAuRkF"
      },
      "source": [
        "# access the dataset from datablock\n",
        "dsets = dblock.datasets(trainval)\n",
        "#dsets.train\n",
        "#dsets.valid"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d772GYXZ5cbF"
      },
      "source": [
        "from collections import Counter\n",
        "label_count = Counter(dsets.train.items.Knum)\n",
        "#label_count.most_common() # check the distribution of seqs per label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUx81Al_8wX5"
      },
      "source": [
        "# 1. calc weights for each label class\n",
        "class_weights = {} # empty dict to be filled with the class weights\n",
        "for label in label_count:\n",
        "    class_weights[label] = 1/label_count[label] # for every category the weight is (1 / number of associated sequences)\n",
        "wgts = dsets.train.items.Knum.map(class_weights).values #[:len(dsets.train)] \n",
        "\n",
        "# check in which order /type weights have to be for the weighted dataloader --> can also check later if it works by looking at batch composition\n",
        "\n",
        "# my case\n",
        "weighted_dls = dblock.dataloaders(trainval,bs=256, dl_type=WeightedDL, wgts=wgts, shuffle=True, drop_last=True) \n",
        "dls.train = weighted_dls.train # replace the train dl with a weighted dl -> comment out before and after histogram visualizing to get comparison"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCZwWA5vCVzb",
        "outputId": "1b83b143-d783-402c-d119-71311cd3cbbe"
      },
      "source": [
        "# check vocab of the dls \n",
        "#dls.vocab\n",
        "dls.c"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV_uBmDOLKyo"
      },
      "source": [
        "# check one batch to make sure the dls is constructed right\n",
        "x,y = dls.one_batch()\n",
        "#y # these should be the targets \n",
        "#x # and these the encoded sequences"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9rClUPdWTGd",
        "outputId": "e7e23c37-6209-4d1f-c297-05ce7e022268"
      },
      "source": [
        "# check the shape\n",
        "x.shape #torch.Size([256, 1, 20, 300]) or torch.Size([256, 3, 20, 300]) depending on which get_x I used (depends on if i get the Resnet to work with 1 input channel)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 3, 20, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7mdK9hiSXB9"
      },
      "source": [
        "# check the label distribution in the batch to see if balancing was successful (note:maybe do a before and after weighing the dataloader)\n",
        "#import matplotlib.pyplot as plt\n",
        "#plt.hist(y,bins=dls.c)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uVa_8Ukt6cOD",
        "outputId": "7d384ba9-68d4-4871-ac28-b4e8218ae34f"
      },
      "source": [
        "# this cell leads to an error later when training: \n",
        "# cell exists to fix the error: RuntimeError: Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same\n",
        "# alt idea: use Model hooks or a callback that changes the input before the forward pass\n",
        "# callback timepoint: before_fit\n",
        "'''# monkey patch to solve error arising from dls changeing tensor type \n",
        "def _conv_forward(self, input, weight):\n",
        "    input= input.type(torch.FloatTensor).cuda() # added this line to change the tensor type # THIS IS THE PROBLEM LATER!!\n",
        "    #input= input.cuda()\n",
        "    if self.padding_mode != 'zeros':\n",
        "        return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
        "                        weight, self.bias, self.stride,\n",
        "                        _pair(0), self.dilation, self.groups)\n",
        "    return F.conv2d(input, weight, self.bias, self.stride,\n",
        "                    self.padding, self.dilation, self.groups)\n",
        "\n",
        "# replace in the module\n",
        "nn.Conv2d._conv_forward = _conv_forward'''"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"# monkey patch to solve error arising from dls changeing tensor type \\ndef _conv_forward(self, input, weight):\\n    input= input.type(torch.FloatTensor).cuda() # added this line to change the tensor type # THIS IS THE PROBLEM LATER!!\\n    #input= input.cuda()\\n    if self.padding_mode != 'zeros':\\n        return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\\n                        weight, self.bias, self.stride,\\n                        _pair(0), self.dilation, self.groups)\\n    return F.conv2d(input, weight, self.bias, self.stride,\\n                    self.padding, self.dilation, self.groups)\\n\\n# replace in the module\\nnn.Conv2d._conv_forward = _conv_forward\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD5oC9tDqYUF"
      },
      "source": [
        "# Prebuilt ResNet from pytorch: Architecture and learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQMX7EvvWDAQ"
      },
      "source": [
        "# callback to fix RuntimeError: Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same\n",
        "def cb(self): \n",
        "    new_xb = [x.type(torch.FloatTensor).cuda() for x in self.learn.xb]\n",
        "    self.learn.xb = new_xb\n",
        "    return self.learn.xb\n",
        "t_type = Callback(before_batch=cb)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHWEPnsBJBEC"
      },
      "source": [
        "# callback to save the model during training\n",
        "smc = SaveModelCallback(monitor=\"error_rate\", fname=\"2D_ResNet50\", comp=np.less, with_opt=True) # with_opt=True"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um7w85KsmGpy"
      },
      "source": [
        "# callback to stop training when the model doesnt improve anymore\n",
        "estop = EarlyStoppingCallback(monitor=\"error_rate\", min_delta=0.001, comp=np.less, patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZrEmDJmbrU4"
      },
      "source": [
        "# the model architecture\n",
        "model = resnet50"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fcHkmJhawFQ"
      },
      "source": [
        "# try just like this with cnn_learner\n",
        "learn = cnn_learner(dls, resnet50, metrics=error_rate, pretrained=False, cbs=[t_type,smc]) # add the callbacks"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vvIEioVZiGc",
        "outputId": "7f83b448-db3c-4e20-df18-dcc69ae014aa"
      },
      "source": [
        "# check if the callbacks are added\n",
        "learn.cbs"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#5) [TrainEvalCallback,Recorder,ProgressCallback,Callback,SaveModelCallback]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N20e6MZJnC-6"
      },
      "source": [
        "# check architecture\n",
        "#learn.model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "WLXXG0_krFqa",
        "outputId": "de0b3ff4-aa0d-48a6-e721-9670eb6c998e"
      },
      "source": [
        "# choose an adequate lr\n",
        "learn.lr_find() # suggest_funcs=(minimum, steep, valley, slide)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(valley=tensor(0.0007))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9Zn48c+TfV+ALJCwy74JREFE1KKiVau2oq22LuNSWkedtuNof522TpeZtrYd6wZuxU5FLQV3K6IWxQWRHWWVNdyELED2fXl+f9yTGEIICeTcJfd5v155Jfec7z3nuXnd3CffXVQVY4wxBiDM3wEYY4wJHJYUjDHGtLKkYIwxppUlBWOMMa0sKRhjjGllScEYY0yrCH8H0F39+vXTIUOG+DsMY4wJKuvWrTukqmknKhd0SWHIkCGsXbvW32EYY0xQEZH9XSlnzUfGGGNaWVIwxhjTypKCMcaYVq72KYhICvAUMB5Q4F9UdVWb88nAs8AgJ5bfq+rC7t6noaEBj8dDbW1tzwQehGJiYsjOziYyMtLfoRhjgpjbHc1/Apap6tUiEgXEtTt/B7BVVS8XkTRgh4gsUtX67tzE4/GQmJjIkCFDEJEeCj14qCqHDx/G4/EwdOhQf4djjAlirjUfObWAWcDTAKpar6ql7YopkCjeT/IE4AjQ2N171dbW0rdv35BMCAAiQt++fUO6pmSM6Rlu9ikMBYqBhSKyQUSeEpH4dmUeAcYA+cBnwN2q2tz+QiJyu4isFZG1xcXFHd4sVBNCi1B//cb0du9sLWRXUYXr93EzKUQAU4D5qjoZqALua1dmDrARGACcDjwiIkntL6SqT6hqjqrmpKWdcO5FwEtISABg3759jB8/3s/RGGOCwfcWrWPp+jzX7+NmUvAAHlVd7TxegjdJtHUz8KJ67QL2AqNdjMlr82L43/Fwf4r3++bFrt/SGGNOVn1jMw1NSlxkuOv3ci0pqGoBcEBERjmHZgNb2xXLdY4jIhnAKGCPWzEB3gTw2l1QdgBQ7/fX7jqlxHDffffx6KOPtj6+//77+dWvfsXs2bOZMmUKEyZM4JVXXun0Gk1NTdxzzz2cccYZTJw4kccffxyAG264gZdffrm13PXXX3/Caxljepea+iYA4qLdX4TC7XkKdwKLRGQz3uah/xaReSIyzzn/S2CGiHwGvAvcq6qHXI3o3V9AQ83RxxpqvMdP0rXXXsvixV8mlcWLF3PjjTfy0ksvsX79elasWMGPfvQjOtv69OmnnyY5OZk1a9awZs0annzySfbu3cstt9zCM888A0BZWRkff/wxl1566UnHaowJPlX13vE38VHu1xRcTTuquhHIaXd4QZvz+cBFbsZwjDJP9453weTJkykqKiI/P5/i4mJSU1PJzMzkBz/4AStXriQsLIy8vDwKCwvJzMzs8BrLly9n8+bNLFmyxBtOWRlffPEFF110Ed///vcpLi5m6dKlfOMb3yAiIuiWrDLGnIJqJyn4oqYQep8uydlO01EHx0/B3LlzWbJkCQUFBVx77bUsWrSI4uJi1q1bR2RkJEOGDOl0yKiq8vDDDzNnzpxjzt1www08++yzvPDCCyxc2O25fcaYIFdV520+8kVNIfSWuZj9M4iMPfpYZKz3+Cm49tpreeGFF1iyZAlz586lrKyM9PR0IiMjWbFiBfv3d75A4Zw5c5g/fz4NDQ0A7Ny5k6qqKgBuuukmHnzwQQDGjh17SnEaY4JPdUufQpTVFHrexGu839/9hbfJKDnbmxBajp+kcePGUVFRQVZWFv379+f666/n8ssvZ8KECeTk5DB6dOeDqm699Vb27dvHlClTUFXS0tJaO5gzMjIYM2YMV1555SnFaIwJTq3NRz6oKUhnnZ+BKCcnR9vvp7Bt2zbGjBnjp4jcV11dzYQJE1i/fj3JycnHLdfbfw/GhKpXN+Vz1/MbeOeHszgtPfGkriEi61S1fR/vMUKv+SjIvPPOO4wZM4Y777yz04RgjOm9qutaagrWfBTyLrjgghP2Rxhjereq+paO5uCfp2CMMeYUtdQUYm30UdcFW99ITwv1129Mb1bd0ERUeBhREe5/ZPeKpBATE8Phw4dD9oOxZT+FmJgYf4dijHFBdV2jT2oJ0Ev6FLKzs/F4PBxvWe1Q0LLzmjGm96mqb/LJxDXoJUkhMjLSdhwzxvRa1fWNPlniAnpJ85ExxvRmVXW+qylYUjDGmABXXd/okzkKYEnBGGMCXnV9E/HRVlMwxhiDNynEWk3BGGMMQFVdo/UpGGOM8aqub7I+BWOMMd7JqVX1jdanYIwxBmobmlH1zQqpYEnBGGMCWssGO72ipiAiKSKyRES2i8g2ETmrgzLnichGEdkiIu+7GY8xxgSblq04YyN7xzIXfwKWqerVIhIFxLU9KSIpwGPAxaqaKyLpLsdjjDFBpaq1puCb5iPX7iIiycAs4CYAVa0H6tsVuw54UVVznTJFbsVjjDHBqKrOW1Pwxf7M4G7z0VCgGFgoIhtE5CkRiW9XZiSQKiLvicg6EbmhowuJyO0islZE1obySqjGmNBT7eOagptJIQKYAsxX1clAFXBfB2WmApcCc4CfisjI9hdS1SdUNUdVc9LS0lwM2RhjAktvqil4AI+qrnYeL8GbJNqXeUtVq1T1ELASmORiTMYYE1RqGpyaQrAPSVXVAuCAiIxyDs0GtrYr9gowU0QiRCQOmAZscysmY4wJNr6uKbideu4EFjkjj/YAN4vIPABVXaCq20RkGbAZaAaeUtXPXY7JGGOCRkufgq822XH1Lqq6Echpd3hBuzIPAA+4GYcxxgSrlpqCr+Yp2IxmY4wJYNX1jcRGhhMeJj65nyUFY4wJYFU+3GAHLCkYY0xAq/HhstlgScEYYwJaVV2jz0YegSUFY4wJaN4NdiwpGGOMAWeDHWs+MsYYA1TXWU3BGGOMo6q+0WdLXIAlBWOMCWg19U3E2ZBUY4wx4K0p2JBUY4wxNDUrtQ3N1qdgjDGmzQY7VlMwxhhTXe8sm219CsYYY1qSgtUUjDHGUFXn7KVgfQrGGGNam4+spmCMMaaqddc1qykYY0zIq66zPgVjjDGO1pqC9SkYY4ypaRl91FtWSRWRFBFZIiLbRWSbiJx1nHJniEijiFztZjzGGBNM/FFTcDv9/AlYpqpXi0gUENe+gIiEA78FlrscizHGBJXquibCBKIjfNeo49qdRCQZmAU8DaCq9apa2kHRO4GlQJFbsRhjTDBqWTZbRHx2TzfTz1CgGFgoIhtE5CkRiW9bQESygKuA+Z1dSERuF5G1IrK2uLjYvYiNMSaAVNf5dtlscDcpRABTgPmqOhmoAu5rV+ZB4F5Vbe7sQqr6hKrmqGpOWlqaO9EaY0yA8fUGO+Bun4IH8KjqaufxEo5NCjnAC07VqB/wVRFpVNWXXYzLGGOCgq832AEXk4KqFojIAREZpao7gNnA1nZlhrb8LCLPAK9bQjDGGC9fb7AD7o8+uhNY5Iw82gPcLCLzAFR1gcv3NsaYoFZd30Sf+Cif3tPVpKCqG/E2EbXVYTJQ1ZvcjMUYY4JNVV0jA1OPGcnvKpvRbIwxAaq6vsmnE9fAkoIxxgSsqrpGny5xAZYUjDEmYNU0WE3BGGMMUN/YTEOTWk3BGGMMVPthMTywpGCMMQGpqnUrTksKxhgT8qrrWmoK1nxkjDEhr6p1gx2rKRhjTMj7sk/BagrGGBPyquucmoIlBWOMMa1bcVrzkTHGmGobfWSMMaZFlY0+MsYY08JqCsYYY1pV1TcSFR5GZLhvP6YtKRhjTAA6XFnv8w12wJKCMcYEpMLyWjKTY3x+X0sKxhgTgA6W1dLfkoIxxhiAgjKrKRhjjAEqahuorGvsfTUFEUkRkSUisl1EtonIWe3OXy8im0XkMxH5WEQmuRmPMcYEg4KyWgAyknyfFNyeFfEnYJmqXi0iUUBcu/N7gXNVtURELgGeAKa5HJMxxgS0g05S6J8c6/N7u5YURCQZmAXcBKCq9UB92zKq+nGbh58A2W7FY4wxwaKgvCUp9K7mo6FAMbBQRDaIyFMiEt9J+VuANzs6ISK3i8haEVlbXFzsRqzGGBMwWpqP0pOifX5vN5NCBDAFmK+qk4Eq4L6OCorI+XiTwr0dnVfVJ1Q1R1Vz0tLS3IrXGGMCwsGyWvolRBEd4dslLsDdpOABPKq62nm8BG+SOIqITASeAq5Q1cMuxmOMMUGhoKzGL8NRwcWkoKoFwAERGeUcmg1sbVtGRAYBLwLfUdWdbsVijDHB5GBZLZl+GHkE7o8+uhNY5Iw82gPcLCLzAFR1AfAzoC/wmIgANKpqjssxGWNMQCsoryVnSKpf7t2lpOB0ENeoarOIjARGA2+qakNnz1PVjUD7D/kFbc7fCtzavZCNMab3qm1oorS6wS/DUaHrzUcrgRgRyQKWA98BnnErKGOMCVUtI4/81XzU1aQgqloNfB14TFXnAuPcC8sYY0LTlxPXAjwpOEtUXA+84Rzz/VgpY4zp5QrKawACfvTRvwE/Bl5S1S0iMgxY4V5YxhgTmlpqCv5KCl3qaFbV94H3AUQkDDikqne5GZgxxoSigrJakmIiiItye3Box7pUUxCR50QkyRmF9DmwVUTucTc0Y4wJPd7Ndfwz8gi63nw0VlXLgSvxrk80FO8IJGOMMT3IX5vrtOhqUogUkUi8SeFVZ36CuheWMcaEpoJy/2zD2aKrSeFxYB8QD6wUkcFAuVtBGWNMKKpvbOZQZZ1fawpd7Wh+CHiozaH9zsqmxhhjekhRRS2q/pu4Bl3vaE4WkT+27GkgIn/AW2swxhjTQwr8PBwVut589GegArjG+SoHFroVlDHGhCJ/bsPZoqsDYYer6jfaPP4vEdnoRkDGGBOqgqmmUCMiM1seiMjZQI07IRljTGg6WFZLXFQ4STH+mbgGXa8pzAP+T0SSncclwI3uhGSMMaGpsNw7R8HZX8Yvujr6aBMwSUSSnMflIvJvwGY3gzPGmFBysKzGryOPoJvbcapquTOzGeCHLsRjjDEhy9+zmeHU9mj2X/3GGGN6maZmpbCizq+zmeHUkoItc2GMMT3kUGUdTc3q9+ajTvsURKSCjj/8BfDfQFpjjOll8kq9AzoHpPj3o7XTmoKqJqpqUgdfiap6wk5qEUkRkSUisl1Etjm7t7U9LyLykIjsEpHNIjLlVF+QMcYEo/wASQpuD4b9E7BMVa8WkSggrt35S4ARztc0YL7z3RhjQkpLUshKDeCawqlw5jTMAp4GUNV6VS1tV+wK4P/U6xMgRUT6uxWTMcYEqvzSWhKjI0iKifRrHK4lBbwb8RQDC0Vkg4g85ezc1lYWcKDNY49zzBhjQoqnpMbvTUfgblKIAKYA81V1MlAF3HcyFxKR21tWaC0uLu7JGI0xJiDkl9YwIMW/I4/A3aTgATyqutp5vARvkmgrDxjY5nG2c+woqvqEquaoak5aWporwRpjjD/ll9X4vT8BXEwKqloAHBCRUc6h2cDWdsVeBW5wRiFNB8pU9aBbMRljTCCqqmuktLohIJqP3B59dCewyBl5tAe4WUTmAajqAuAfwFeBXUA1cLPL8RhjTMBpHXnU25OCqm4EctodXtDmvAJ3uBmDMcYEukCZuAbu9ikYY4zpgvxS7+Y6gVBTsKRgjDF+lldaTXiYkJ4Y7e9QLCkYY4y/5ZfWkpkUQ0S4/z+S/R+BMcaEuLzSmoBoOgJLCsYY43eBMnEN3B+SanpI7uFq3t9ZxHs7ivksr4w54zL53nnDA2K0gjHm5DU1KwVltQHzt2xJIcDtKKjg/730Gev2lwAwqE8ckwam8MKaXF5Yk8s1OQOZd+5wBvZpvwCtMSYYFFXU0tislhRM5+oam3h0xW7mv7eLxJhI/vPSMVwwJoMh/bxrCuaV1vDYil0sXnuA5z7N5ZwRaVybM5ALxqYTHRHu5+iNMV0VKEtmt7CkEGDKqht4a0sBT36why+KKrlqchY/vWwsfeKjjiqXlRLLr6+awL9+5TSe//QAS9Ye4I7n1tMnPoqvT87im2cO4rT0BD+9CmNMV+UF0BwFsKQQEJqblWVbCnhxvYf3dxbT0KQM7RfPwpvP4PxR6Z0+t39yLD+8cCR3zx7Bh7sO8bc1ufxl1T6e+nAvZw7pw4VjM6isa+RwVR2HK+uJjQwnKzWWASmxZKfGclp6AplJMYiIb16sMeYoeSXemkL/ZOtoDnmqysovDvHbN7ez9WA5/ZNjuGnGEC6fNIAJWcnd+qAODxPOHZnGuSPTOFRZx9J1Hl5Yc4Bf/2MbIpAaF0Wf+Chq6pso2FRLU/OXW28nxkQwIj2BkRmJX35lJpCWEH3CGOobm/k8v4wDR6rJPVzNgZJqoiPCOS09gRHpCWSnxlFUUcu+w9XsP1xFTGQ4l03sz+C+7bfWMCY05ZfWkBQTQaKfN9dpId7lh4JHTk6Orl271t9hnLLdxZX89OXP+Xj3YQb2ieVHF47ia5MGEBbWc/+xqypHqupJjo08alJMY1MzBeW15B6pZldRJV8UVrKzsIKdhRWUVDe0lkuJi2RkeiIjMhIYnpbAwD5xDOwTS/+kWNbnlvDGZwdZvqWA8trG1uekJUZTW99ERV0j7YUJtOSiqYNTufL0ASTHRVFZ20hFbQMiMCozibH9k0gLgJmdxvjCLc+sIb+sljfvPsfV+4jIOlVtvxbdMaym0AVL13n4dO8Rco9Uk3ukmrKaBrJTYxmWFs+QvvGcfVo/Zgzv2+X/7D/PK+M7T3u3mbj/8rFcN20wURE9P2VEROibcOyHa0R4GNmpcWSnxjFjeL/W46rKocp6dhZWsKOggi+KKvmisILXNuUf9cHfIjEmggvHZnDR2AxOc2oFMZHhqCpFFXV8UViJp6SajKQYBvf13q+4so6XN+Tx0oY8fvrKluPGnpYYTWJ0BLUNTdQ1NhMWJnxlVDpXTB7A9KF9ezR5GuNPeaU1ZAdIJzOEcE3hUGUdAP06+NBsa/mWAm7/6zr6xkcxuG8cg/rEkRwbyYGSGvYdqiL3SDWNzcqojET+ZeYQrjg9i/KaBrbkl7Mlv4zYqAi+PjmLVKejeM2+I/zLwjUkxUby3G3TgqIZRVU5XFWPp6QGT0k1+aU1nJaewNmn9TvpkU6qyp5DVTQ3K4kxkSTGRNDYpGwrKGdrfjlbD5ZT19hMdEQY0RFhlNc28s9thVTVN5GZFMM3pmbxnelDyAyQdlhjTtaE+9/iqslZ/OKK8a7ep6s1hZBNCtc9+Ql1jc0s/d6M45apqG3gwj+uJCUuktfunElkB+uS1DY08dqmfJ7+cC/bCyqIDBcamo7+nUZFhHH5xAFMHZzKL17fwoCUWBbdOo3+yYHz30EwqKlv4u1thby8IY/3dhQRJsJlE/tzy8xhTMhO9nd4xnRbeW0DE+9fzn2XjGbeucNdvZc1H3VCVdnsKaOyrpHiirrjtl//YflOCitqmf/tKR0mBICYyHDm5gzk6qnZrNpzmOVbChnYJ47xA5IYMyCJg6W1PPvJfl5c72Hpeg9j+ifx11vOPGENxRwrNiqcr00awNcmDSD3cDULP97L4jUHeHljPkP6xnHeqHTOH53OGUNSiYsKybe2CTIHA2w4KoRoUvCU1FDpdIS+t6OIuTkDjymzPreEv6zax41nDWHyoNQTXlNEmDG831Ft9ABJmZH88srx3HvJaN7bUcQ5I9JIjg2MUQbBbFDfOH5++Th+cOFIXtmYzz+3FfL8p7k88/E+AGIjw+kTH0VKXCRJMZHER0eQGBNBelI0c6cOtDkcJiDklVYDgbG5TouQTArbCyoA72iYFR0khYamZn689DMyk2L49zmjOrpEtyVER3DZxAE9ci3zpaSYSL4zfTDfmT6Y2oYmVu0+zNaD5ZRU1XOkup6SqnoqahvxlFRTVd9IQVktj7+/h3NHpnHz2UOYNSLNOq2N3wTaxDUI1aRwsByASycO4L3tRTQ0NR/VPPTnD/eyo7CCp27IISE6JH9FQSkmMpzzR3ubkI7nUGUdz63O5a+f7OemhWuIjwpnWFoCw9LiGZGewHmj0hk3IMkm8xmfyC+tITI8MDbXaRGSn3jbCyoY3DeOyyb257VN+azZd6S12ae2oYknP9jDrJFpXDA2w8+Rmp7WLyGau2aPYN65w3nz84NsyC1ld3Ela/eV8MrGfH6/fCdZKbHMGZfJjOF9ye4TS1ZKbMBMLDK9S35pDZnJMQFVW3U1KYjIPqACaAIa2/d8i0gy8CwwyInl96q60M2YALYXlDMqI5GZp/UjKjyMFduLWpPC0vUeDlXW8z2XRwIY/4qKCOOK07O44vSs1mNHqup5Z1shb31ewLOr9/Pnj/a2nkuOjWTa0D5cMCaD80en2+Q60yO+KKxkSIANS/dFTeF8VT10nHN3AFtV9XIRSQN2iMgiVa13K5jahib2Hqri0okDiI+OYNqwPvxzexE/uXQsTc3KUx/sZVJ2MtOH9XErBBOg+sRHcU3OQK7JGUhlXSM7CyvIK6khv7SGfYereH9HMcu3FiIC04b24Z45o5g62N4n5uTUNjSxo7CC744a5u9QjuLv5iMFEsXbgJsAHAGOnTrbg74orKRZYUxmIgDnj0rnF69vJfdwNVsPlrH3UBWPXjfF2pRDXEJ0BFMGpTKlzcgzVWXrwXLe2VrEotX7+cb8VVw6sT/3XTza9rMw3bb1YDlNzcrE7BR/h3IUt7fjVGC5iKwTkds7OP8IMAbIBz4D7lbVZjcD2lbg7WQe3T8JgK84nZL/3F7I/Pf3MKhPHBePz3QzBBOkRIRxA5K5+4IRrPj387h79gje3VbI7D+8zw//tpF3thZS19jk7zBNkNh8oBSASQMDa+Kl2zWFmaqaJyLpwNsisl1VV7Y5PwfYCHwFGO6U+UBVy9texEkotwMMGjTolALafrCCmMgwBjn/2Q3pF8+wfvE8vnIPB8tq+eWV4wkPoE4fE5jioyP4wYUj+daZg3jon1/w+qZ8XtyQR0J0BOePTmdSdjJjByQxrn8yyXHWSW2OtdlTRr+EaDKTAmupFleTgqrmOd+LROQl4EygbVK4GfiNetfa2CUie4HRwKftrvME8AR4l7k4lZh2FHo7mdt+8J8/Op2nP9xLn/go5k7NPpXLmxCTmRzDf181gfsvH8eqPYd587ODrNhRxGub8lvLjMxI4OJxmcwZn8nY/l0Y7rp5Mbz7CyjzQHI2zP4ZTLzG5VdifG1zXhmTsru3RL4vuJYURCQeCFPVCufni4BftCuWC8wGPhCRDGAUsMetmFSVbQcruHDM0UNNZztJ4cazhhATaVtZmu6Lighr3c8CoLiijq0HvYsirtxZzCMrdvHQP3eRnRrLOSP6MX1YX6YN7Xvsgn6bF8Nrd0GDd+MVyg54H4Mlhl6ksq6R3cWVXB6AE1rdrClkAC85WTACeE5Vl4nIPABVXQD8EnhGRD4DBLi3k5FKp6y4so4jVfWM7p941PGzhvflkesmc8EYm5dgekZaYjTnJnqTxPfPO43DlXW8s62Qt7cW8vrmgzz/6QEAslNjGZ2ZxOhM774VFyz7GfEtCaFFQ4235mBJodf4zFOGKkwMwIUcXUsKqroHmNTB8QVtfs7HW4Pwie0HvctbjM5MOuq4iNgSFMZVfROiufaMQVx7xiCampVtB8tZtfswGz2l7CioYMWOIpqalT3RB73/HrWjZR60WQNqkpM5eZ/leTuZQyopBKIdBS1JIfEEJY1xT3iYMD4rmfFZX34g1DY0sf9wNc2Lsgmr8BzznLzmvlz1P++2NlHNPK1f6x4dJvhs8pSRlRLb4SZY/hZSSWFbQTkZSdH2x2QCTkxkOKMyE+HCnx/dpwBoZCyFk/6DaeV9eHtrIUvWeZNGalwkA1K8y3BMGpjC1VOzyQiwkSymY5s9pQFZS4AQSwrbD1Yc03RkTEBp6TdoM/pIZv+MqROvYSrQ1Kxs8pSyes+R1l3w9h6qYvnWQv749k4uGJPOt84cxLkj0wJuVIvxKqmq58CRGq47c7C/Q+lQyCSFhqZmdhVVcs7IficubIw/TbzmuJ3K4WFyzExrgH2Hqnh+TS5L1np4a0shc8Zl8MDcSSTZQn4BZ3NeGQCTArSm4PaM5oCx91AV9U3N1p9geqUh/eL58SVj+PjHX+EnXx3DO9uKuOKRj1r70UzgaJnJPN6Sgn9tL+h45JExvUl0RDi3zRrG87dNp6K2kSsf/YhXNub5OyzTxua8Mob1iw/YWlzIJIVZI/qx8OYzGJ5m2zCa3u/MoX14466ZjBuQxN0vbOSHizdSUdvg77AMgd3JDCGUFFLiojh/VDpRESHzkk2Iy0iK4fnbp3PX7BG8vCGPS/70AWv2HfF3WCGtsLyWwvK6gFsZtS37hDSmF4sMD+OHF47k7/NmECbCtY+v4qcvf05Rea2/QwtJq3YfBmDSQEsKxhg/mjo4lX/cfQ7XTxvM85/mMuuBFfx22XZKq13bz8p04PlPcxnUJ47JlhSMMf6WEB3BL68czzs/PJeLx2Wy4P3dzPrdCl7a4MG7ULFx066iClbvPcJ10wYF9HIllhSMCTFD+sXz4Dcn8+bd5zAyI5Ef/G0Tdzy3niNVVmtw06LVuUSGS8Avz29JwZgQNTozib999yzuvXg0b28t5KL/XcmKHUX+DqtXqm1oYuk6DxeP7x+Q6x21ZUnBmBAWHiZ877zhvPqvM+mXEMXNC9fwwFvbaWxydVfckPP65oOU1zZy/bRT2znSFywpGGMY0z+Jl+84m2+eMZBHV+zmO09/SlGFjVDqKYtW72d4WjzThvbxdygnZEnBGAN4V2r9zTcm8vu5k9hwoIRLH/qQT/Yc9ndYQW9Lfhkbcku5ftrgoFik0JKCMeYoV0/N5uU7ziYxOoLrnvyER1fsornZRiedrOdW5xIdEcY3pgR2B3MLSwrGmGOMzkzi1TtncunEATzw1g5ufmaNjU46SW9vLeTCsRkkxwXmWkftWVIwxnQoITqCh755Or+6cjyrdh/m0oc+YN3+En+HFVRqG5ooqqhjZEbwrM5sScEYc1wiwrenD+bF788gIty7TMbCj/baZLcuyiv17qA3sE+snyPpOsD/mlwAAA6BSURBVFeTgojsE5HPRGSjiKw9TpnznPNbROR9N+Mxxpyc8VnJvP6v53DeqHT+67Wt/OvzG6isa/R3WAHPU+JNCtmpcX6OpOt8sfPa+ap6qKMTIpICPAZcrKq5IpLug3iMMSchOS6SJ74zlSc+2MPvlm1nW345j317iu1R0okDR6oByE61mkJXXQe8qKq5AKpq0ymNCWBhYcK8c4fz3G3TqajzbuLz97UH/B1WwPKU1BAZLmQkxvg7lC5zOykosFxE1onI7R2cHwmkish7TpkbXI7HGNMDpg/ryxt3zWTywFTuWbKZe5dspr7RZkG35ympJislNqAXwGvP7eajmaqa5zQLvS0i21V1Zbv7TwVmA7HAKhH5RFV3tr2Ik1BuBxg0KPCniRsTCtITY3j21mn88e0dPLpiN3mlNcz/9hQSA3SbSX84UFITVP0J4HJNQVXznO9FwEvAme2KeIC3VLXK6XdYCUzq4DpPqGqOquakpaW5GbIxphvCw4R75ozmgasn8smew1zz+CcU2gY+rfJKqoOqPwFcTAoiEi8iiS0/AxcBn7cr9gowU0QiRCQOmAZscysmY4w75uYM5OmbzmD/4Sq+/tjH7Cqq8HdIfldT38ShynoG9rGaQosM4EMR2QR8CryhqstEZJ6IzANQ1W3AMmCzU+YpVW2fOIwxQeDckWks/u5Z1DU2c/WCVWzIDe2Jbp6S4Bt5BC4mBVXdo6qTnK9xqvpr5/gCVV3QptwDqjpWVcer6oNuxWOMcd/4rGSWfu8skmMjue7J1SG9P8OXcxQsKRhjQtjgvvEsmTeD4enx3PqXtSxd5/F3SH7RUlMYaB3NxphQl5YYzfO3TWf6sD786O+b+MlLn1EVYjOgPSU1REWE0S/Ad1prz5KCMcYViTGR/PmmM7jtnKE892kul/zpA9bsO+LvsHzmQEk12UE2RwEsKRhjXBQdEc5PLh3LC7dNR1GueXwVv39rR0jsz+ApqSEryPoTwJKCMcYHpg3ry5t3z+LqKdk8smIXdzy3npr6Jn+H5SpPSU3QDUcFSwrGGB9JiI7gd1dP5D8vHcOyLQV888lPeu0+0FV1jRypqg+6kUdgScEY40Miwq3nDGPBt6eys6CCqx79mM2eUn+H1eOCccnsFpYUjDE+N2dcJou/exZNzcrXH/uYh9/9gsam3rOg3pfDUa2mYIwxXTIhO5m3/m0Wl0zozx/e3sncx1ex91CVv8PqEVZTMMaYk5AcF8nD35rMn755OruLKpnz4Ep+/cZWSqvr/R3aKTlwpJqYyDD6JUT5O5Rus6RgjPG7K07PYvkPzuVrkwbw1Id7mfW7FSx4fze1DcE5QsnjLJktElxzFMCSgjEmQGQmx/D7uZN48+5zmDo4ld+8uZ2Zv13B4+/vDrrZ0J7S4Fsyu4UlBWNMQBmdmcTCm89k8XfPYkz/RP7nze2c/dt/8vC7X1BW3eDv8LrkwJEaSwrGGNOTzhzah7/eMo2Xvj+DqYNS+cPbO5nxm3f59RtbKSgLrPkNdY1NqHpnaZfXNlBW0xCUnczg/nacxhhzSiYPSuXpm85g28FyHn9/N3/+aB/PfLyPyyYO4NvTBzFlUKpf2+4/zyvjW098wuj+ifz88nGEO2sdBdvqqC2kJbsFi5ycHF27dq2/wzDG+MmBI9U8/eFelqzzUFnXyOjMRK6fNoivT8kmPtq3/+fmldZw1aMfIQKNTcqR6npOH5jChtxSXrnjbCYNTPFpPJ0RkXWqmnPCcpYUjDHBqKqukdc25fPs6v18nldOUkwE100bzI0zBtM/2f32/PLaBubOX0V+WQ1LvzeDzOQYHn73CxZ+tI/GZmX9Ty+kT3zgDEm1pGCMCRnrc0t4+oO9vPn5QcJEOG9UGlMH9+H0gSlMyE6mrKaBfYeq2HuoitqGJiYPSmF8VjLREeHHXKuovJZXN+XzysZ8co9Ut/YVRISHMTE7mZmn9eOs4X35739sY/WeI/zfv5zJjNP6tT5/T3Elew9VMXtMhs9ef1dYUjDGhJwDR6pZ+NE+VuwoOuHs6KiIME7PTiE9KZowEcIEiivrWLX7MM0Kk7KTOX1gSmt/RU19E2v2H2FP8ZfX/f3cSVw9NdvV19RTLCkYY0JaSVU9Gz2lbM0vJyUukqF94xnSL57I8DDW7S9h7b4jrMstoaymAVVoViUmIpyLxmVw5eQshqcldHjd/NIaPtp1iNiocC6bOMDHr+rkWVIwxhjTqqtJwdV5CiKyT0Q+E5GNInLcT3IROUNEGkXkajfjMcYY0zlfjN86X1UPHe+kiIQDvwWW+yAWY4wxnQiEGc13AkuBIn8HYowxoc7tpKDAchFZJyK3tz8pIlnAVcD8zi4iIreLyFoRWVtcXOxSqMYYY9xOCjNVdQpwCXCHiMxqd/5B4F5V7XTLJVV9QlVzVDUnLS3NrViNMSbkudqnoKp5zvciEXkJOBNY2aZIDvCCMw64H/BVEWlU1ZfdjMsYY0zHXEsKIhIPhKlqhfPzRcAv2pZR1aFtyj8DvG4JwRhj/MfNmkIG8JJTC4gAnlPVZSIyD0BVF7h4b2OMMSch6CaviUgxsB9IBsqcwyf6ueV7P+C4w2M70faaXT1/omPBEHNnj3s65pOJ92Rj7uhYsMQcCO+L48V4othDJeZAfS8PVtUTd8qqalB+AU909ec239ee6r26ev5Ex4Ih5s4e93TMJxPvycZ8nGNBEXMgvC+68l4I5ZiD8b3c9isQ5imcrNe68XPbY6d6r66eP9GxYIi5s8c9HfPJxNvR8a7EfLzX0V3+iDkQ3hftjwXDe7n9MXsvH0fQNR+dChFZq11Y+yOQWMy+EWwxB1u8YDH7yqnGHMw1hZPxhL8DOAkWs28EW8zBFi9YzL5ySjGHVE3BGGNM50KtpmCMMaYTlhSMMca0sqRgjDGmlSUFh4icIyILROQpEfnY3/F0hYiEicivReRhEbnR3/F0hYicJyIfOL/r8/wdT1eISLyzSu9l/o6lK0RkjPP7XSIi3/N3PF0hIleKyJMi8jcRucjf8XSFiAwTkadFZIm/Yzke5737F+d3e31XntMrkoKI/FlEikTk83bHLxaRHSKyS0Tu6+waqvqBqs4DXgf+4ma8TmynHDNwBZANNAAet2JtE1tPxKxAJRCDyzH3ULwA9wKL3YnyaD30Xt7mvJevAc52M14ntp6I+WVVvQ2YB1zrZrxObD0R8x5VvcXdSI/Vzdi/Dixxfrdf69INTmXmW6B8AbOAKcDnbY6FA7uBYUAUsAkYC0zA+8Hf9iu9zfMWA4nBEDNwH/Bd57lLgiTmMOd5GcCiIIj3QuCbwE3AZcHwO3ae8zXgTeC6YInZed4fgClBFrPrf3unEPuPgdOdMs915fq+2I7Tdaq6UkSGtDt8JrBLVfcAiMgLwBWq+j9Ah80AIjIIKFPVChfDBXomZhHxAPXOwyb3ovXqqd+zowSIdiPOFj30Oz4PiMf7B1YjIv/QE+z/4e+Yneu8CrwqIm8Az7kVr3Ovnvg9C/Ab4E1VXe9mvNDj72Wf6k7seGvj2cBGutgy1CuSwnFkAQfaPPYA007wnFuAha5FdGLdjflF4GEROYej96nwpW7FLCJfB+YAKcAj7obWoW7Fq6o/ARCRm4BDbiaETnT3d3we3maDaOAfrkZ2fN19L98JXAAki8hp6p9VlLv7e+4L/BqYLCI/dpKHvxwv9oeAR0TkUrq4DEZvTgrdpqo/93cM3aGq1XgTWdBQ1RfxJrOgoqrP+DuGrlLV94D3/BxGt6jqQ3g/wIKGqh7G2wcSsFS1Cri5O8/pFR3Nx5EHDGzzONs5FsgsZvcFW7xgMftKMMbcosdi781JYQ0wQkSGikgU3s7CV/0c04lYzO4LtnjBYvaVYIy5Rc/F7stecxd7458HDvLl0MxbnONfBXbi7ZX/ib/jtJgtXos5ML6CMWZfxW4L4hljjGnVm5uPjDHGdJMlBWOMMa0sKRhjjGllScEYY0wrSwrGGGNaWVIwxhjTypKC6RVEpNLH9+uRPTfEu79EmYhsFJHtIvL7LjznShEZ2xP3N6Y9SwrGdEBEOl0XTFVn9ODtPlDV04HJwGUicqI9EK7Eu2qrMT3OkoLptURkuIgsE5F14t3tbbRz/HIRWS0iG0TkHRHJcI7fLyJ/FZGPgL86j/8sIu+JyB4RuavNtSud7+c555c4/+kvcpaBRkS+6hxbJyIPicjrncWrqjV4lzjOcp5/m4isEZFNIrJUROJEZAbevRIecGoXw4/3Oo05GZYUTG/2BHCnqk4F/h14zDn+ITBdVScDLwD/0eY5Y4ELVPVbzuPReJf6PhP4uYhEdnCfycC/Oc8dBpwtIjHA48Alzv3TThSsiKQCI/hyGfQXVfUMVZ0EbMO7nMHHeNe0uUdVT1fV3Z28TmO6zZbONr2SiCQAM4C/O/+4w5eb+mQDfxOR/nh3qdrb5qmvOv+xt3hDVeuAOhEpwrtjXPttRD9VVY9z343AELxbju5R1ZZrPw/cfpxwzxGRTXgTwoOqWuAcHy8iv8K790QC8FY3X6cx3WZJwfRWYUCp01bf3sPAH1X1VWdDmvvbnKtqV7auzc9NdPw305UynflAVS8TkaHAJyKyWFU3As8AV6rqJmeTn/M6eG5nr9OYbrPmI9MrqWo5sFdE5oJ3u0cRmeScTubLteZvdCmEHcCwNtsmnnAzeqdW8RvgXudQInDQabK6vk3RCufciV6nMd1mScH0FnEi4mnz9UO8H6S3OE0zW/DuWQvemsHfRWQdcMiNYJwmqO8Dy5z7VABlXXjqAmCWk0x+CqwGPgK2tynzAnCP01E+nOO/TmO6zZbONsYlIpKgqpXOaKRHgS9U9X/9HZcxnbGagjHuuc3peN6Ct8nqcT/HY8wJWU3BGGNMK6spGGOMaWVJwRhjTCtLCsYYY1pZUjDGGNPKkoIxxphWlhSMMca0+v8vldoT1yF4hgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "KfvuekQIrCa3",
        "outputId": "88e76576-6c78-4e0e-8be5-ec1889fb9c3d"
      },
      "source": [
        "# train \n",
        "epochs=3\n",
        "lr=0.0007 # based on valley in lr_find \n",
        "learn = learn.fit_one_cycle(epochs, lr)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      66.67% [2/3 32:55<16:27]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.319508</td>\n",
              "      <td>0.550956</td>\n",
              "      <td>0.142620</td>\n",
              "      <td>16:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.058364</td>\n",
              "      <td>0.134808</td>\n",
              "      <td>0.035851</td>\n",
              "      <td>16:23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='31' class='' max='1498' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      2.07% [31/1498 00:18<14:38 0.0548]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with error_rate value: 0.1426202803850174.\n",
            "Better model found at epoch 1 with error_rate value: 0.03585059195756912.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.319508</td>\n",
              "      <td>0.550956</td>\n",
              "      <td>0.142620</td>\n",
              "      <td>16:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.058364</td>\n",
              "      <td>0.134808</td>\n",
              "      <td>0.035851</td>\n",
              "      <td>16:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.021453</td>\n",
              "      <td>0.076114</td>\n",
              "      <td>0.020167</td>\n",
              "      <td>16:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 2 with error_rate value: 0.020167261362075806.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4V-9alTU6bM",
        "outputId": "9ce94ce5-ff88-4543-ad1b-db0eeaf9869f"
      },
      "source": [
        "# load the model (is it possible to continue training?)\n",
        "learn.load('2D_ResNet50') \n",
        "# model summary print out\n",
        "# do lr_find again before continuing training"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastai/learner.py:56: UserWarning: Saved filed doesn't contain an optimizer state.\n",
            "  elif with_opt: warn(\"Saved filed doesn't contain an optimizer state.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.learner.Learner at 0x7f49b3ee6c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6JfF9y31q8Qa",
        "outputId": "aaa30636-2f60-49f3-c010-e709db749e11"
      },
      "source": [
        "# confusion matrix -> given an error, not enough RAM on colab. \n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDuZZNUxaHAV"
      },
      "source": [
        "# doesnt work as after simply training (and not reloading learn) -> AttributeError: 'NoneType' object has no attribute 'export'\n",
        "# save the architecture and the parameters\n",
        "# learn.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCx0vtzwaX0E"
      },
      "source": [
        "# load the model not for training but for making predictions (inference)\n",
        "learn_inf = load_learner(path/'modelname.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUxQmrbhalet"
      },
      "source": [
        "# make prediction\n",
        "learn_inf.predict('images/grizzly.jpg') # image as example\n",
        "'''returned three things: the predicted category in the same format you originally provided \n",
        "(in this case, thatâ€™s a string), the index of the predicted category, and the probabilities of each category\n",
        "The last two are based on the order of categories in the vocab of the DataLoaders '''\n",
        "# check vocab\n",
        "learn_inf.dls.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm5dMN3Ee-nA"
      },
      "source": [
        "# This cell is to find a way for the Resnet to accept 1 channel input, it is maybe not needed if I simply change my input data instead\n",
        "\n",
        "'''# Note: DONT LIKE THIS AS IT OVERWRITES THE FORWARD function and doesnt allow me to use cnn_learner\n",
        "# define a custom resnet and change the first layer to adapt for your input shape:\n",
        "#import torch.nn as nn\n",
        "class MyResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=1):\n",
        "        super(MyResNet, self).__init__()\n",
        "\n",
        "        # bring resnet\n",
        "        #self.model = torchvision.models.resnet50()\n",
        "        self.model = resnet50\n",
        "\n",
        "        # original definition of the first layer on the resnet class --> CHECK THIS AGAIN\n",
        "        # self.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        \n",
        "        # my case\n",
        "        self.model.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "my_resnet50 = MyResNet()\n",
        "\n",
        "# try just like this with cnn_learner\n",
        "learn2 = Learner(dls, my_resnet50, metrics=error_rate) \n",
        "# check architecture\n",
        "learn2.model'''"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWIj7EZZnGWJ"
      },
      "source": [
        "# Architechture for a 2D ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ruonptT32Ol"
      },
      "source": [
        "class ConvLayer(nn.Sequential):\n",
        "    \"Create a sequence of convolutional (`ni` to `nf`), ReLU (if `use_activ`) and `norm_type` layers.\"\n",
        "    @delegates(nn.Conv2d)\n",
        "    def __init__(self, ni, nf, ks=3, stride=1, padding=None, bias=None, ndim=2, norm_type=NormType.Batch, bn_1st=True,\n",
        "                 act_cls=defaults.activation, transpose=False, init='auto', xtra=None, bias_std=0.01, **kwargs):\n",
        "        if padding is None: padding = ((ks-1)//2 if not transpose else 0)\n",
        "        bn = norm_type in (NormType.Batch, NormType.BatchZero)\n",
        "        inn = norm_type in (NormType.Instance, NormType.InstanceZero)\n",
        "        if bias is None: bias = not (bn or inn)\n",
        "        conv_func = _conv_func(ndim, transpose=transpose)\n",
        "        conv = conv_func(ni, nf, kernel_size=ks, bias=bias, stride=stride, padding=padding, **kwargs)\n",
        "        act = None if act_cls is None else act_cls()\n",
        "        init_linear(conv, act, init=init, bias_std=bias_std)\n",
        "        if   norm_type==NormType.Weight:   conv = weight_norm(conv)\n",
        "        elif norm_type==NormType.Spectral: conv = spectral_norm(conv)\n",
        "        layers = [conv]\n",
        "        act_bn = []\n",
        "        if act is not None: act_bn.append(act)\n",
        "        if bn: act_bn.append(BatchNorm(nf, norm_type=norm_type, ndim=ndim))\n",
        "        if inn: act_bn.append(InstanceNorm(nf, norm_type=norm_type, ndim=ndim))\n",
        "        if bn_1st: act_bn.reverse()\n",
        "        layers += act_bn\n",
        "        if xtra: layers.append(xtra)\n",
        "        super().__init__(*layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16s7WOmy3qyD"
      },
      "source": [
        "# https://github.com/fastai/fastai/blob/08a639548fd82ff22b7a72db9519f82b176511d7/fastai/layers.py#L461\n",
        "class ResBlock(Module):\n",
        "    \"Resnet block from `ni` to `nh` with `stride`\"\n",
        "    @delegates(ConvLayer.__init__)\n",
        "    def __init__(self, expansion, ni, nf, stride=1, groups=1, reduction=None, nh1=None, nh2=None, dw=False, g2=1,\n",
        "                 sa=False, sym=False, norm_type=NormType.Batch, act_cls=defaults.activation, ndim=2, ks=3,\n",
        "                 pool=AvgPool, pool_first=True, **kwargs):\n",
        "        norm2 = (NormType.BatchZero if norm_type==NormType.Batch else\n",
        "                 NormType.InstanceZero if norm_type==NormType.Instance else norm_type)\n",
        "        if nh2 is None: nh2 = nf\n",
        "        if nh1 is None: nh1 = nh2\n",
        "        nf,ni = nf*expansion,ni*expansion\n",
        "        k0 = dict(norm_type=norm_type, act_cls=act_cls, ndim=ndim, **kwargs)\n",
        "        k1 = dict(norm_type=norm2, act_cls=None, ndim=ndim, **kwargs)\n",
        "        convpath  = [ConvLayer(ni,  nh2, ks, stride=stride, groups=ni if dw else groups, **k0),\n",
        "                     ConvLayer(nh2,  nf, ks, groups=g2, **k1)\n",
        "        ] if expansion == 1 else [\n",
        "                     ConvLayer(ni,  nh1, 1, **k0),\n",
        "                     ConvLayer(nh1, nh2, ks, stride=stride, groups=nh1 if dw else groups, **k0),\n",
        "                     ConvLayer(nh2,  nf, 1, groups=g2, **k1)]\n",
        "        if reduction: convpath.append(SEModule(nf, reduction=reduction, act_cls=act_cls))\n",
        "        if sa: convpath.append(SimpleSelfAttention(nf,ks=1,sym=sym))\n",
        "        self.convpath = nn.Sequential(*convpath)\n",
        "        idpath = []\n",
        "        if ni!=nf: idpath.append(ConvLayer(ni, nf, 1, act_cls=None, ndim=ndim, **kwargs))\n",
        "        if stride!=1: idpath.insert((1,0)[pool_first], pool(stride, ndim=ndim, ceil_mode=True))\n",
        "        self.idpath = nn.Sequential(*idpath)\n",
        "        self.act = defaults.activation(inplace=True) if act_cls is defaults.activation else act_cls()\n",
        "\n",
        "    def forward(self, x): return self.act(self.convpath(x) + self.idpath(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JutmnTDH9lmc"
      },
      "source": [
        "the following parts are from the book"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YuryrLFqO1V"
      },
      "source": [
        "# the resblock\n",
        "def _conv_block(ni,nf,stride): \n",
        "    return nn.Sequential(\n",
        "        ConvLayer(ni, nf, stride=stride),\n",
        "        ConvLayer(nf, nf, act_cls=None, norm_type=NormType.BatchZero))\n",
        "    \n",
        "class ResBlock(Module):\n",
        "    def __init__(self, ni, nf, stride=1):\n",
        "        self.convs = _conv_block(ni,nf,stride)\n",
        "        self.idconv = noop if ni==nf else ConvLayer(ni, nf, 1, act_cls=None) \n",
        "        self.pool = noop if stride==1 else nn.AvgPool2d(2, ceil_mode=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return F.relu(self.convs(x) + self.idconv(self.pool(x)))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j5tlY6J9zGo"
      },
      "source": [
        "# the stem\n",
        "def _resnet_stem(*sizes): \n",
        "    return [\n",
        "        ConvLayer(sizes[i], sizes[i+1], 3, stride = 2 if i==0 else 1) for i in range(len(sizes)-1)\n",
        "    ] + [nn.MaxPool2d(kernel_size=3, stride=2, padding=1)]\n",
        "\n",
        "_resnet_stem(1,3,32,32,64) # just add 1, to add the first layer to increate to 3 channels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRbchCws9lIN"
      },
      "source": [
        "# putting it all together\n",
        "class ResNet(nn.Sequential):\n",
        "    def __init__(self, n_out, layers, expansion=1):\n",
        "        stem = _resnet_stem(1,3,32,32,64) # added 1, here to have initial layer with 1 channel\n",
        "        self.block_szs = [64, 64, 128, 256, 512]\n",
        "        for i in range(1,5): self.block_szs[i] *= expansion \n",
        "        blocks = [self._make_layer(*o) for o in enumerate(layers)] \n",
        "        super().__init__(*stem, *blocks,\n",
        "                        nn.AdaptiveAvgPool2d(1), Flatten(),\n",
        "                        nn.Linear(self.block_szs[-1], n_out))\n",
        "\n",
        "    def _make_layer(self, idx, n_layers): \n",
        "        stride = 1 if idx==0 else 2\n",
        "        ch_in,ch_out = self.block_szs[idx:idx+2] \n",
        "        return nn.Sequential(*[\n",
        "            ResBlock(ch_in if i==0 else ch_out, ch_out, stride if i==0 else 1)\n",
        "            for i in range(n_layers) \n",
        "        ])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKczPgzNnaa0"
      },
      "source": [
        "def get_learner(m):\n",
        "    return Learner(dls, m, loss_func=nn.CrossEntropyLoss(), metrics=accuracy).to_fp16()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XALWLkBe-ooc"
      },
      "source": [
        "# this would be a ResNet18\n",
        "rn = ResNet(dls.c, [2,2,2,2])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm8Kn_M9m4D5"
      },
      "source": [
        "learn = get_learner(rn)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83nOjpYxvW6e"
      },
      "source": [
        "epochs=1\n",
        "lr=0.1\n",
        "learn = learn.fit_one_cycle(epochs, lr) # TypeError: _conv_forward() takes 3 positional arguments but 4 were given"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p980-ZaenvjY"
      },
      "source": [
        "#rn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uOAaE1yzK4P"
      },
      "source": [
        "ResNet with bottleneck design"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq9yIpG70n2t"
      },
      "source": [
        "??_conv_forward"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fldh5XTAzJiL"
      },
      "source": [
        "def _conv_block(ni,nf,stride): \n",
        "    return nn.Sequential(\n",
        "        ConvLayer(ni, nf//4, 1),\n",
        "        ConvLayer(nf//4, nf//4, stride=stride),\n",
        "        ConvLayer(nf//4, nf, 1, act_cls=None, norm_type=NormType.BatchZero))\n",
        "\n",
        "class ResBlock(Module):\n",
        "    def __init__(self, ni, nf, stride=1):\n",
        "        self.convs = _conv_block(ni,nf,stride)\n",
        "        self.idconv = noop if ni==nf else ConvLayer(ni, nf, 1, act_cls=None) \n",
        "        self.pool = noop if stride==1 else nn.AvgPool2d(2, ceil_mode=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return F.relu(self.convs(x) + self.idconv(self.pool(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3teXKRkszOyY"
      },
      "source": [
        "rn = ResNet(dls.c, [3,4,6,3], 4)\n",
        "learn = get_learner(rn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruDM4KOrzfYS"
      },
      "source": [
        "learn.fit_one_cycle(20, 3e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFmVi9etau7f"
      },
      "source": [
        "futehrmore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSTLvD_dIrmS"
      },
      "source": [
        "# monkey patch to solve TypeError: _conv_forward() takes 3 positional arguments but 4 were given\n",
        "def forward(self, input: Tensor) -> Tensor:\n",
        "    #print(\"start\",input,\"end\")\n",
        "    print(input.shape) # torch.Size([1, 3, 32, 32])\n",
        "    return self._conv_forward(input, self.weight, self.bias) # what is the 4th argument??\n",
        "# replace in the module\n",
        "nn.Conv2d.forward = forward"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9A3rk83lYjK"
      },
      "source": [
        "m = nn.Conv2d(16, 33, 3, stride=2)\n",
        "input = torch.randn(20, 16, 50, 100) # the shape of the input is not the problem\n",
        "output = m(input) # when i run it not on gpu it works, but on it it doesnt"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gca6kvrWn15n"
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}