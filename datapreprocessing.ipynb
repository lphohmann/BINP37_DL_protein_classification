{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "datapreprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NZCWPDr7YtOYArWhshJR3UT3Pk3AgPFm",
      "authorship_tag": "ABX9TyOBGdrwsIe1t40HQ9dw4bH5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lphohmann/DL_microbial_gene_classifier/blob/main/datapreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdbSyE1eU_Qs",
        "outputId": "dcb1436b-7a15-4376-e9e6-46def53d564e"
      },
      "source": [
        "# mount google drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ILm-n3GV1fE",
        "outputId": "b7494651-cb4c-4439-cbae-5c180c68fad2"
      },
      "source": [
        "%cd drive/MyDrive/ColabNotebooks/DL_project/\n",
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/DL_project\n",
            "/content/drive/MyDrive/ColabNotebooks/DL_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z3RLemwPJCB"
      },
      "source": [
        "# prepare the training, validation and test set\n",
        "# modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# input file in fasta format\n",
        "input_file = 'CH4_database_protein.faa'\n",
        "\n",
        "'''\n",
        "Step 1: load the fasta file with the protein seqeunces and k numbers into a pandas dataframe\n",
        "'''\n",
        "\n",
        "# create dictionary from input fasta file where K number is key and the associated seqs the values\n",
        "def knum_dict(file):\n",
        "    k_dic = {}\n",
        "    with open(file) as input_file:\n",
        "        for line in input_file:\n",
        "            if line.startswith('>'):\n",
        "                header = line.split()[1]\n",
        "                prot_seq = next(input_file).strip().upper()\n",
        "                seq_list = []\n",
        "                seq_list.append(prot_seq)\n",
        "                if header not in k_dic.keys():\n",
        "                    k_dic[header] = list()\n",
        "                else:\n",
        "                    pass\n",
        "                k_dic[header].extend(seq_list)\n",
        "            else:\n",
        "                print(\"This should never appear, if yes the file is in the wrong format\")\n",
        "                break\n",
        "    return k_dic\n",
        "\n",
        "# create the pandas dataframe based on that dictionary\n",
        "def dict_to_df(dict):\n",
        "    x = [item[0] for item in dict.items()] # save all keys in a list\n",
        "    df1 = pd.DataFrame({'Knum': x[0], 'Seq': dict[x[0]]}) # create initial dataframe\n",
        "    for key in x[1:]: # now for the rest of the keys\n",
        "        df2 = pd.DataFrame({'Knum': key, 'Seq': dict[key]}) # for each kay make a dataframe\n",
        "        df1 = pd.concat([df1,df2]) # concatenate them\n",
        "    return df1.reset_index(drop=True) # have to reset index as it is mixed up after concat\n",
        "\n",
        "# running code\n",
        "k_dic = knum_dict(input_file)\n",
        "k_df = dict_to_df(k_dic)\n",
        "\n",
        "# filter out K numbers with less than X (e.g. 500) associated sequences from the dataframes\n",
        "min_seq_cutoff = 500\n",
        "filt_k_df = k_df.groupby(\"Knum\").filter(lambda x: len(x) > min_seq_cutoff)\n",
        "\n",
        "'''\n",
        "Step 2: Stratified random split based (group by) K num column of the pd df into training, validation and test set.\n",
        "'''\n",
        "\n",
        "# the data is first split into a set from which the training and validation set will be created and the test set\n",
        "trainval, test = train_test_split(filt_k_df, test_size=0.1, random_state=42, stratify=filt_k_df[['Knum']])\n",
        "\n",
        "# This step is moved to the DataBlock step when loading my data for the model\n",
        "# Then the trainval set is split into training and validation set (80/20)\n",
        "#training, validation = train_test_split(trainval, test_size=0.2, random_state=42, stratify=trainval[['Knum']])\n",
        "\n",
        "# save these dfs in .csv files\n",
        "#training.to_csv('training.csv')\n",
        "#validation.to_csv('validation.csv')\n",
        "trainval.to_csv('trainval.csv')\n",
        "test.to_csv('test.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPF_BMNyqhia",
        "outputId": "7a79b5a6-ab61-4e10-82e6-a9c4407d8f8a"
      },
      "source": [
        "# check same stats about the data to set some parameters for the transform functions\n",
        "# the max sequence length\n",
        "print(\"max sequence length:\",filt_k_df.Seq.map(len).max()) #2818\n",
        "# the unique characters in the sequences\n",
        "distinc_list = []\n",
        "for key in k_dic:\n",
        "    distinc_list.append(\"{}{}\".format(k_dic[key][0],k_dic[key][1]))\n",
        "distinct_aa = set(''.join(distinc_list))\n",
        "print(distinct_aa) # {'K', 'D', 'N', 'E', 'R', 'A', 'T', 'L', 'I', 'Q', 'C', 'F', 'G', 'W', 'M', 'S', 'H', 'P', 'V', 'Y'}\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max sequence length: 2818\n",
            "{'K', 'D', 'N', 'E', 'R', 'A', 'T', 'L', 'I', 'Q', 'C', 'F', 'G', 'W', 'M', 'S', '*', 'H', 'P', 'V', 'Y'}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}