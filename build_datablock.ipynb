{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "build_datablock.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/c55ly3fHZRSPxgpMcsKU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lphohmann/DL_microbial_gene_classifier/blob/main/build_datablock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQFnDp2fo-H_"
      },
      "source": [
        "#hide\n",
        "# do i need this still? \n",
        "#!pip install fastai --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT3j2jdYk2gy"
      },
      "source": [
        "#hide\n",
        "!pip install torchtext==0.8.1\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFzbFyx1k3Q7"
      },
      "source": [
        "#hide\n",
        "import fastai\n",
        "from fastbook import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E-3B33Y5x84"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pvbcIQBeiBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c38e2b-063f-4557-e10c-39794a8d2ff3"
      },
      "source": [
        "# mount google drive to access files and set the correct working\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd drive/MyDrive/ColabNotebooks/DL_project/\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ColabNotebooks/DL_project\n",
            "/content/drive/MyDrive/ColabNotebooks/DL_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt4nOCS3GgBj"
      },
      "source": [
        "# cell to check function documentation\n",
        "??nn.Conv2d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXfQhg_9FvoR"
      },
      "source": [
        "# read in my data from which training and validation set will be created\n",
        "trainval = pd.read_csv('trainval.csv', low_memory=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2HWIqpvBdER"
      },
      "source": [
        "# defining functions required for building the DataBlock\n",
        "# one hot encoding function\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def OH_enc(seq: str):\n",
        "    # get the categories into array\n",
        "    cats = ['K', 'D', 'N', 'E', 'R', 'A', 'T', 'L', 'I', 'Q', 'C', 'F', 'G', 'W', 'M', 'S', 'H', 'P', 'V', 'Y']\n",
        "    cat_array = np.array(sorted(cats), ndmin=1) #\n",
        "    # get seq into array\n",
        "    seq_array = np.array(list(seq))\n",
        "    #one hot encode the sequence\n",
        "    onehot_encoder = OneHotEncoder(categories=[cat_array],sparse=False,handle_unknown='ignore')\n",
        "    onehot_encoded_seq = onehot_encoder.fit_transform(seq_array.reshape(len(seq_array), 1))\n",
        "    return np.transpose(onehot_encoded_seq)\n",
        "\n",
        "# zero padding function\n",
        "def pad_along_axis(array: np.ndarray, target_length: int, axis: int = 0):\n",
        "    pad_size = target_length - array.shape[axis]\n",
        "    if pad_size <= 0:\n",
        "        return array\n",
        "    npad = [(0, 0)] * array.ndim\n",
        "    npad[axis] = (0, pad_size)\n",
        "    return np.pad(array, pad_width=npad, mode='constant', constant_values=0)\n",
        "\n",
        "# combine in one function\n",
        "def main_item_tfms(seq): # added -> None because the tensor shape later is 1,2820 and i think it should be 20,2820\n",
        "    enc_seq = OH_enc(seq)\n",
        "    pad_encseq_array = pad_along_axis(enc_seq,2820,1)\n",
        "    return pad_encseq_array \n",
        "\n",
        "# categorize function\n",
        "tcat = Categorize(vocab=['K00024', 'K00121', 'K00122', 'K00123', 'K00124', 'K00126',\n",
        "       'K00127', 'K00148', 'K00169', 'K00170', 'K00171', 'K00172',\n",
        "       'K00194', 'K00196', 'K00197', 'K00198', 'K00200', 'K00201',\n",
        "       'K00202', 'K00317', 'K00320', 'K00441', 'K00600', 'K00625',\n",
        "       'K00672', 'K00830', 'K00925', 'K01007', 'K01070', 'K01499',\n",
        "       'K01595', 'K01895', 'K03388', 'K03389', 'K03390', 'K05979',\n",
        "       'K06034', 'K08097', 'K08691', 'K08692', 'K09733', 'K10713',\n",
        "       'K10714', 'K11212', 'K11261', 'K11779', 'K11780', 'K12234',\n",
        "       'K13039', 'K13788', 'K14067', 'K14080', 'K14083', 'K14940',\n",
        "       'K14941', 'K15228', 'K15229', 'K18277'])\n",
        "\n",
        "# questoin, do i have to also apply the ToTensor()? https://docs.fast.ai/tutorial.pets.html\n",
        "# -> answer : I think ToTensor() is always applied, like to float tensor\n",
        "tconv = ToTensor()\n",
        "# try to add this as well (add a batch_tfms (or after_batch_tfms) line to DataBlock)\n",
        "#batch_tfms = [IntToFloatTensor(), Normalize.from_stats(mean,std)]\n",
        "tofloat = IntToFloatTensor()\n",
        "\n",
        "# get_x and y by specifying column in dataframe\n",
        "def get_y(r): return tcat(r['Knum']) # apply the categorize trasnform \n",
        "\n",
        "# maybe add another dimension here, which is the number of channels (later needed)\n",
        "def get_x(r): # apply the one hot encoding and padding function\n",
        "    return np.expand_dims(main_item_tfms(r['Seq']),0) # this should add a dimension at 0\n",
        "\n",
        "# building the datablock\n",
        "dblock = DataBlock(\n",
        "                 splitter = TrainTestSplitter(test_size=0.2, random_state=42, stratify=trainval[['Knum']]),\n",
        "                 get_x = get_x,\n",
        "                 get_y = get_y,\n",
        "                 item_tfms = tconv,\n",
        "                 batch_tfms = tofloat\n",
        "                 )\n",
        "\n",
        "# checking it\n",
        "#dblock.summary(trainval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7m3DBkE8Rb-"
      },
      "source": [
        "# create dataloaders from datablock \n",
        "dls = dblock.dataloaders(trainval,bs=256) # not sure how to choose the batch size\n",
        "#dls.to(device=default_device, dtype=torch.float)\n",
        "# dataloaders changes the tensor type of y to double because it is 1D but i need float\n",
        "# unqueeze 1 extra dimension before the minibatch is created and then squeeze it (remove) in the conv.py code\n",
        "# so create a transform that does that \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nONx3O7TSleL",
        "outputId": "19d5677c-46ae-4ec9-b116-bb0978b4d1c5"
      },
      "source": [
        "# check one batch to make sure the dls is constructed right\n",
        "x,y = dls.one_batch()\n",
        "#y # these should be the targets \n",
        "#x # and these the encoded sequences\n",
        "\n",
        "# check the shape\n",
        "x.shape, y.shape # torch.Size([256, 1, 20, 2820]), batch size,channel,height, width \n",
        "#type(x)#, type(y)\n",
        "#  Conv2d layers expect input with the shape (n_samples, channels, height, width) \n",
        "# e.g., (1000, 1, 224, 224) so add a channel dimension in get_x\n",
        "# tensor = tensor.unsqueeze(1)  # adds a dimensions at the specified index.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 1, 20, 2820]), torch.Size([256]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-vtH_fjz6Ud"
      },
      "source": [
        "change the kernels.\n",
        "way to check the dimensions of the tensor\n",
        "i think its 20x2820 (set to 20 kernels now). Also what should be the input for the output in each layer (20x20 to how many output nodes)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V61x6O6MX8t"
      },
      "source": [
        "# monkey patch attempt\n",
        "def _conv_forward(self, input, weight):\n",
        "    input= input.type(torch.FloatTensor)\n",
        "    input= input.cuda()\n",
        "    if self.padding_mode != 'zeros':\n",
        "        return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
        "                        weight, self.bias, self.stride,\n",
        "                        _pair(0), self.dilation, self.groups)\n",
        "    return F.conv2d(input, weight, self.bias, self.stride,\n",
        "                    self.padding, self.dilation, self.groups)\n",
        "\n",
        "# replace in the module\n",
        "nn.Conv2d._conv_forward = _conv_forward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLK2F6kFMR0J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "ca2e5ad6-91a5-46f8-8e2c-44a530cff8c5"
      },
      "source": [
        "# model 3\n",
        "# alt. cov function with batchnorm layer \n",
        "def conv(ni, nf, ks=(21, 9), act=True): # i think a non square kernel makes more sense\n",
        "    # note: better to apply different stride (e.g. (2,1))?\n",
        "    layers = [nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=(ks[0]//2,ks[1]//2))] # (3, 5), stride=(2, 1), padding=(4, 2) # padding=ks//2)\n",
        "    layers.append(nn.BatchNorm2d(nf))\n",
        "    if act: layers.append(nn.ReLU())\n",
        "    return nn.Sequential(*layers)\n",
        "# the model\n",
        "def simple_cnn(): \n",
        "    return sequential(  # start \n",
        "        conv(1 ,8), # 1 input channel, 8 convolutions\n",
        "        conv(8 ,16),  \n",
        "        conv(16,32),  \n",
        "        conv(32,64),  \n",
        "        conv(64,128),\n",
        "        conv(128,58, act=False),  \n",
        "        Flatten(),\n",
        "    )\n",
        "# fit\n",
        "def fit(epochs=1, lr=0.06):\n",
        "    learn = Learner(dls, simple_cnn(), loss_func=F.cross_entropy,\n",
        "                        metrics=accuracy, cbs=ActivationStats(with_hist=True))\n",
        "    learn.fit_one_cycle(epochs, lr) # make training more stable with fit_one_cycle\n",
        "    return learn\n",
        "# fit the model\n",
        "learn = fit()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastai/callback/core.py:50: UserWarning: You are shadowing an attribute (modules) that exists in the learner. Use `self.learn.modules` to avoid this\n",
            "  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='866' class='' max='1498' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      57.81% [866/1498 31:46<23:11 2.9277]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.784333</td>\n",
              "      <td>2.793497</td>\n",
              "      <td>0.288484</td>\n",
              "      <td>1:05:41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6buH_O0Nei4E"
      },
      "source": [
        "# model 3 checking\n",
        "# checking activation\n",
        "learn.activation_stats.plot_layer_stats(-2) # check activations at the end, shouldnt be near zero\n",
        "learn.activation_stats.color_dim(-4)\n",
        "# view learning rate\n",
        "learn.recorder.plot_sched()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIZMh5iRyhsK"
      },
      "source": [
        "# train for more epochs\n",
        "learn = fit(5, lr=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGpHv_pH3gxx"
      },
      "source": [
        "# check what mistakes the model is making (classifying one category mistakenly as another one)\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOU7FNSJ5CBX",
        "cellView": "form"
      },
      "source": [
        "#@title alternative model\n",
        "# model 2\n",
        "from fastai.callback.hook import *\n",
        "# conv function\n",
        "def conv(ni, nf, ks=20, act=True):\n",
        "    # input - input tensor of shape (minibatch, in_channels, iH, iW) height and width of the image \n",
        "    # weight - filters of shape (out_channels, in_channels, kH, kW) height and width of our kernel\n",
        "    res = nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2) \n",
        "    if act: res = nn.Sequential(res, nn.ReLU())\n",
        "    return res\n",
        "# the model\n",
        "def simple_cnn(): \n",
        "    return sequential(\n",
        "        conv(1 ,8, ks=5), #14x14 \n",
        "        conv(8 ,16), #7x7 \n",
        "        conv(16,32), #4x4 \n",
        "        conv(32,64), #2x2 \n",
        "        conv(64,58, act=False), #1x1 # 58 would correstpond to the number of categories\n",
        "        Flatten(),\n",
        "    )\n",
        "# fit\n",
        "def fit(epochs=1, lr=0.06):\n",
        "    learn = Learner(dls, simple_cnn(), loss_func=F.cross_entropy,\n",
        "                        metrics=accuracy, cbs=ActivationStats(with_hist=True))\n",
        "    learn.fit_one_cycle(epochs, lr) # make training more stable with fit_one_cycle\n",
        "    return learn\n",
        "\n",
        "# checing things\n",
        "simple_cnn(xb).shape # 2nd field shoudl correspond to number of possible outcomes\n",
        "# fit the model\n",
        "learn = fit()\n",
        "learn.summary()\n",
        "# checking activation\n",
        "learn.activation_stats.plot_layer_stats(-2) # check activations at the end, shouldnt be near zero\n",
        "learn.activation_stats.color_dim(-4)\n",
        "# view learning rate\n",
        "learn.recorder.plot_sched()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}