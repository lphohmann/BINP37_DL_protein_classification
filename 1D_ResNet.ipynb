{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1D_ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Q6c9t37zYlS0",
        "UjbgfwgeYqfB",
        "b98f0GqJSm9Q"
      ],
      "authorship_tag": "ABX9TyMQHvJxr19HoDD3PL72PJAv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lphohmann/DL_microbial_gene_classifier/blob/main/1D_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6c9t37zYlS0"
      },
      "source": [
        "# Setting everything up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLoMrgCjYlS7"
      },
      "source": [
        "%%capture\n",
        "# installing fastai\n",
        "!pip install fastai --upgrade"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFsoEIVWYlS8"
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from fastai import *\n",
        "from fastai.vision.all import *\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D118gfuuYlS9",
        "outputId": "34daa175-7005-45ff-e32f-e6ab70a2da7b"
      },
      "source": [
        "# mount google drive to access files and set the correct working directory\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd drive/MyDrive/DL_project/\n",
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/DL_project\n",
            "/content/drive/MyDrive/DL_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjbgfwgeYqfB"
      },
      "source": [
        "# Define functions required for creating the Datablock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWhRflf_YqfE"
      },
      "source": [
        "# defining transform functions required for correctly loading the data when building the DataBlock\n",
        "\n",
        "# one hot encoding function\n",
        "def OH_enc(seq: str):\n",
        "    # get the categories into array\n",
        "    cats = ['K', 'D', 'N', 'E', 'R', 'A', 'T', 'L', 'I', 'Q', 'C', 'F', 'G', 'W', 'M', 'S', 'H', 'P', 'V', 'Y']\n",
        "    cat_array = np.array(sorted(cats), ndmin=1) #\n",
        "    # get seq into array\n",
        "    trunc_seq = seq[:300] # truncate sequences longer than 300 \n",
        "    seq_array = np.array(list(trunc_seq))\n",
        "    # one hot encode the sequence\n",
        "    onehot_encoder = OneHotEncoder(categories=[cat_array],sparse=False,handle_unknown='ignore')\n",
        "    onehot_encoded_seq = onehot_encoder.fit_transform(seq_array.reshape(len(seq_array), 1))\n",
        "    return np.transpose(onehot_encoded_seq)\n",
        "\n",
        "# zero padding function that makes sure the encoded sequences are all of the same format later\n",
        "def pad_along_axis(array: np.ndarray, target_length: int, axis: int = 0):\n",
        "    pad_size = target_length - array.shape[axis]\n",
        "    if pad_size <= 0:\n",
        "        return array\n",
        "    npad = [(0, 0)] * array.ndim\n",
        "    npad[axis] = (0, pad_size)\n",
        "    return np.pad(array, pad_width=npad, mode='constant', constant_values=0)\n",
        "\n",
        "# combine in one function\n",
        "def main_item_tfms(seq): \n",
        "    enc_seq = OH_enc(seq)\n",
        "    pad_encseq_array = pad_along_axis(enc_seq,300,1)\n",
        "    return pad_encseq_array "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtRGsGMCY9Qq"
      },
      "source": [
        "# functions to get x and y data\n",
        "def get_y(r): return r['Knum'] # y are the labels in the Knum column in the dataframe\n",
        "def get_x(r): return main_item_tfms(r['Seq']) # x are the sequences in the Seq column; the transform functinos are applied"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F03yODg-YqfI"
      },
      "source": [
        "# defining the TransformBlock for single-label categorical targets to be used to apply additional transforms when building the datablock\n",
        "def CategoryBlock(vocab=None, sort=True, add_na=False):\n",
        "    return TransformBlock(type_tfms=Categorize(vocab=vocab, sort=sort, add_na=add_na))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSd5LpFgZHXl"
      },
      "source": [
        "# Create the dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsYPsgVGYqfH"
      },
      "source": [
        "# read in my data from which training and validation set will be created\n",
        "trainval = pd.read_csv('data/trainval.csv', low_memory=False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWuI9RzSlXwW"
      },
      "source": [
        "# building the datablock, which acts as a template on how to load the data\n",
        "dblock = DataBlock(blocks=(TransformBlock(batch_tfms=IntToFloatTensor), CategoryBlock()),\n",
        "                   splitter = TrainTestSplitter(test_size=0.2, random_state=42, stratify=trainval[['Knum']]), # stratified split the trainval df into 80% train and 20% valid set\n",
        "                   get_x = get_x,\n",
        "                   get_y = get_y)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9nXl6DvYqfL"
      },
      "source": [
        "# checking/debugging the datablock \n",
        "#dblock.summary(trainval)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTESBqfOZHXm"
      },
      "source": [
        "# create dataloaders from datablock \n",
        "dls = dblock.dataloaders(trainval, bs=256, shuffle=True, drop_last=True) # shuffle the data to prevent overfitting due to an organized dataset and drop the last incomplete batch"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arZeSZlmZHXn"
      },
      "source": [
        "# visualize batch label distribution, compare with hist after batch balance correction\n",
        "x,y = dls.one_batch()\n",
        "#plt.hist(y,bins=dls.c) # if run with gpu there is a type error so this has to run in a different session"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51xVxDwBZHXo"
      },
      "source": [
        "# access the dataset from datablock\n",
        "dsets = dblock.datasets(trainval)\n",
        "#dsets.train\n",
        "#dsets.valid"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmOwIMZ7DFS1"
      },
      "source": [
        "# label distribution in valid set\n",
        "valid_label_count = Counter(dsets.valid.items.Knum)\n",
        "#valid_label_count.most_common() # check the distribution of seqs per label"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcHmGZCeZHXq"
      },
      "source": [
        "# label distribution in train set\n",
        "train_label_count = Counter(dsets.train.items.Knum)\n",
        "#train_label_count.most_common() # check the distribution of seqs per label"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8hMjO-zZHXq"
      },
      "source": [
        "# calc. weights for each label class\n",
        "class_weights = {} # empty dict to be filled with the class weights\n",
        "for label in train_label_count:\n",
        "    class_weights[label] = 1/train_label_count[label] # for every category the weight is (1 / number of associated sequences)\n",
        "wgts = dsets.train.items.Knum.map(class_weights).values[:len(dsets.train)] \n",
        "weighted_dls = dblock.dataloaders(trainval,bs=256, dl_type=WeightedDL, wgts=wgts, shuffle=True, drop_last=True) \n",
        "dls.train = weighted_dls.train # replace the train dl with a weighted dl\n",
        "# in the end the train dls is balanced and the valid dls is unbalanced -> later a suitable metric has to be chosen"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvXF_MDrZHXr"
      },
      "source": [
        "# exploring if the dls was corretly constructed - 1\n",
        "# check dls attributes .c and .vocab \n",
        "#dls.vocab\n",
        "#dls.c"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1qkot2mZHXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d137b8f3-3c8d-4c76-8021-b996d42eba28"
      },
      "source": [
        "# exploring if the dls was corretly constructed - 2\n",
        "# check one batch to make sure the dls is constructed right (balanced)\n",
        "x,y = dls.one_batch()\n",
        "#y # these should be the targets \n",
        "#x # and these the encoded sequences\n",
        "# check the shape\n",
        "x.shape #torch.Size([256, 20, 300])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 20, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQhoZsyKZHXv"
      },
      "source": [
        "# check the label distribution in the batch to see if balancing was successful, compare with the previous histogram\n",
        "#x,y = dls.one_batch()\n",
        "#plt.hist(y,bins=dls.c)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b98f0GqJSm9Q"
      },
      "source": [
        "# Functions for the Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGZHTGu3_qWh"
      },
      "source": [
        "# the metric \n",
        "# choose one that is also fine for unbalanced datasets such as the F1score\n",
        "F1Score = F1Score(average='macro') # 'macro' calculate score for each label individually, and then find their unweighted mean. penalizes poor performance on minority classes more"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQMX7EvvWDAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9c580655-ea81-4e25-a9d9-e9d163554402"
      },
      "source": [
        "'''\n",
        "# callback that changes the tensor type of x to fix RuntimeError: Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same\n",
        "def cb(self): \n",
        "    new_xb = [x.type(torch.FloatTensor).cuda() for x in self.learn.xb]\n",
        "    self.learn.xb = new_xb\n",
        "    return self.learn.xb\n",
        "TensorTypeChange = Callback(before_batch=cb)\n",
        "'''"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# callback that changes the tensor type of x to fix RuntimeError: Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same\\ndef cb(self): \\n    new_xb = [x.type(torch.FloatTensor).cuda() for x in self.learn.xb]\\n    self.learn.xb = new_xb\\n    return self.learn.xb\\nTensorTypeChange = Callback(before_batch=cb)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2-ibRrE_nkM"
      },
      "source": [
        "class TensorTypeChange(Callback): \n",
        "    def before_batch(self):\n",
        "        new_xb = [x.type(torch.FloatTensor).cuda() for x in self.learn.xb]\n",
        "        self.learn.xb = new_xb\n",
        "        return self.learn.xb"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHWEPnsBJBEC"
      },
      "source": [
        "# callback to save the model during training\n",
        "smc = SaveModelCallback(monitor=\"f1_score\", fname=\"1D_ResNet152\", comp=np.greater, with_opt=True) # change comp based on metric"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um7w85KsmGpy"
      },
      "source": [
        "# callback to stop training after x epochs when the model doesnt improve anymore\n",
        "estop = EarlyStoppingCallback(monitor=\"f1_score\", comp=np.greater, patience=10) # note: change comp based on chosen metric"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iplifuzXWvq"
      },
      "source": [
        "# function to get the learner\n",
        "def get_learner(m): # .to_fp16()\n",
        "    return Learner(dls, m, loss_func=nn.CrossEntropyLoss(), opt_func=Adam, lr=defaults.lr, cbs=[TensorTypeChange,smc,estop], metrics=[accuracy,F1Score], model_dir='models') "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZAOtjQ3W86-"
      },
      "source": [
        "# Bottleneck resnet: Book-based architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCJ-vGmcXHvq"
      },
      "source": [
        "# the resnet stem\n",
        "def _resnet_stem(*sizes): \n",
        "    return [\n",
        "        ConvLayer(sizes[i], sizes[i+1], 3, stride = 2, ndim=1 if i==0 else 1) for i in range(len(sizes)-1) # ndim\n",
        "    ] + [nn.MaxPool1d(kernel_size=3, stride=2, padding=1)] # 1d\n",
        "\n",
        "# test\n",
        "#m = _resnet_stem(20,32,32,64) # just add 20, to add the first layer to increate to 20 channels"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk_K4o_ca13t"
      },
      "source": [
        "# the conv block definition and ResBlock\n",
        "def _conv_block(ni,nf,stride): \n",
        "    return nn.Sequential(\n",
        "        ConvLayer(ni, nf//4, 1, ndim=1), # ndim\n",
        "        ConvLayer(nf//4, nf//4, stride=stride, ndim=1), #\n",
        "        ConvLayer(nf//4, nf, 1, act_cls=None, norm_type=NormType.BatchZero, ndim=1)) #\n",
        "\n",
        "class ResBlock(Module):\n",
        "    def __init__(self, ni, nf, stride=1):\n",
        "        self.convs = _conv_block(ni,nf,stride)\n",
        "        self.idconv = noop if ni==nf else ConvLayer(ni, nf, 1, act_cls=None, ndim=1) # ndim\n",
        "        self.pool = noop if stride==1 else nn.AvgPool1d(2, ceil_mode=True) # changed to 1d\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return F.relu(self.convs(x) + self.idconv(self.pool(x)))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDAPie5zXK7o"
      },
      "source": [
        "# putting it all together\n",
        "class ResNet(nn.Sequential):\n",
        "    def __init__(self, n_out, layers, expansion=1):\n",
        "        stem = _resnet_stem(20,32,32,64) # \n",
        "        self.block_szs = [64, 64, 128, 256, 512]\n",
        "        for i in range(1,5): self.block_szs[i] *= expansion \n",
        "        blocks = [self._make_layer(*o) for o in enumerate(layers)] \n",
        "        super().__init__(*stem, *blocks,\n",
        "                        nn.AdaptiveAvgPool1d(1), Flatten(), #1d\n",
        "                        nn.Linear(self.block_szs[-1], n_out))\n",
        "\n",
        "    def _make_layer(self, idx, n_layers): \n",
        "        stride = 1 if idx==0 else 2\n",
        "        ch_in,ch_out = self.block_szs[idx:idx+2] \n",
        "        return nn.Sequential(*[\n",
        "            ResBlock(ch_in if i==0 else ch_out, ch_out, stride if i==0 else 1)\n",
        "            for i in range(n_layers) \n",
        "        ])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsHI0okdXbKp"
      },
      "source": [
        "# defining the architecture\n",
        "rn = ResNet(dls.c, [3, 8, 36, 3], 4) # this would be a resnet152\n",
        "# get the learner\n",
        "learn = get_learner(rn)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZyfo_X5XRof"
      },
      "source": [
        "# checking the model architecture\n",
        "#learn.model"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86_qLySZX6ss"
      },
      "source": [
        "# Bottleneck resnet: Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSDIKhiIXzcm"
      },
      "source": [
        "# choose an adequate lr\n",
        "learn.lr_find(suggest_funcs=(minimum, steep, valley, slide)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1RLtEGgX3xt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "ced26598-5b02-4575-d05d-45900b1cf445"
      },
      "source": [
        "# training the model\n",
        "epochs=1\n",
        "lr=0.00010964782268274575 # based on valley in lr_find \n",
        "learn.fit_one_cycle(epochs, lr) #, cbs=[TensorTypeChange] # moved TensorTypeChange callback from learner to fit, potentially change it back and change cb construction"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.232764</td>\n",
              "      <td>1.982613</td>\n",
              "      <td>0.485873</td>\n",
              "      <td>0.444906</td>\n",
              "      <td>11:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with f1_score value: 0.4449060949002532.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O0rt-c8N0aO"
      },
      "source": [
        "# call learn.export to save all the information of our Learner object for inference\n",
        "# SaveModelCallback loads the best model at the end so the best model is exported\n",
        "#learn = learn.to_fp32()\n",
        "learn.export(fname='export.pkl') # to_fp32 otherwise when loading the model for inference it gives a type error"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59-iz-nLkCov"
      },
      "source": [
        "# testing on the testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kbdw3ssOq9q"
      },
      "source": [
        "\n",
        "2. i dont get an error in the training but when i predict for inference?\n",
        "3. check confusion matrix for the old good model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDZtjbaoUOTd"
      },
      "source": [
        "# slightly change the TensorTypeCallback so that the input is no longer put on gpu (as the weights arent either here)\n",
        "# removed the .cuda() \n",
        "class TensorTypeChange(Callback): \n",
        "    def before_batch(self):\n",
        "        new_xb = [x.type(torch.FloatTensor) for x in self.learn.xb] # removed the .cuda() \n",
        "        self.learn.xb = new_xb\n",
        "        return self.learn.xb"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk8zLLJTkeaw"
      },
      "source": [
        "# load the learner containing the template on how to load data\n",
        "learn_inf = load_learner('export.pkl')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEVRz-I5_2OB",
        "outputId": "d5eaaeb5-e0a5-4275-d561-896eb50b9789"
      },
      "source": [
        "# try to reomve the callbacks that are not needed anymore\n",
        "learn_inf.cbs"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#4) [TrainEvalCallback,Recorder,ProgressCallback,TensorTypeChange]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbMmr6G3BUgT",
        "outputId": "57928923-fb42-417c-f733-9cc005609f06"
      },
      "source": [
        "# remove non required callbacks\n",
        "learn_inf.remove_cbs([SaveModelCallback,EarlyStoppingCallback]) #TensorTypeChange,"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.learner.Learner at 0x7fa49eaac410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a-9qZwEHp_q"
      },
      "source": [
        "# read in my data from which training and validation set will be created\n",
        "test_df = pd.read_csv('data/test.csv', low_memory=False)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMsbbNVmmVFf"
      },
      "source": [
        "# create test dataloader\n",
        "test_dl = learn_inf.dls.test_dl(test_df, with_labels=True) # based on dblock template"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXHIfNFIYtYv",
        "outputId": "3d8d4b91-319f-4d04-de7b-5e9dd3321c03"
      },
      "source": [
        "#x,y=test_dl.one_batch()\n",
        "#len(x) # 256\n",
        "len(test_dl.dataset) # 53277"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53277"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xnu8oBUAU9gx",
        "outputId": "bcd73d2c-57fa-43d4-dad9-5d68d76686de"
      },
      "source": [
        "# Validate on dl\n",
        "#%debug  \n",
        "learn_inf.validate(dl=test_dl) # IndexError: list index out of range -> problem with test set? or have to move to gpu?\n",
        "# have to move weights and inputs to gpu?\n",
        "# OR REMOVE THE CALLBACKS THAT ARE NOT NEEDED LIKE SAVEMODEL AND ENDEARLY!!!\n",
        "# AttributeError: 'ResNet' object has no attribute 'conv1' after removing callbacks; when i load the model before there is no such error\n",
        "# RuntimeError: expected scalar type Double but found Float -> after removing the three callbacks, NOT if i leave my tensortype transfrom in\n",
        "# ES FUNKTIONIERT WENN ICH DIE BEIDEN CALLBACKS RAUSNEHME WOHOoOOoOoOO"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [2.016101598739624,0.47423842549324036,0.42689778043463666]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcNVhT4KKVe7"
      },
      "source": [
        "# get preds or validate # no error after changing callback (i guess for inference the model doesnt go on gpu)\n",
        "preds,y=learn_inf.get_preds(dl=test_dl) # list index out of range"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZR8mU1yojnr"
      },
      "source": [
        "# Bottleneck resnet: Confusion matrix and model loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkmcxDFTb0JZ"
      },
      "source": [
        "alternatively just try to remove the loss function from learn_inf to get the test set CM?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FapsGEDUZzcz"
      },
      "source": [
        "# to plot the construction matrix, the learner has to be constructed without the loss function (otherwise it gives an assertion error)\n",
        "def get_learner(m):\n",
        "    return Learner(dls, m, opt_func=Adam, lr=defaults.lr, cbs=[TensorTypeChange,smc], metrics=[accuracy,F1Score], model_dir='models') # no loss function provided (unclear on exact cause)\n",
        "# architecture\n",
        "rn = ResNet(dls.c, [3, 8, 36, 3], 4) # resnet152\n",
        "learn = get_learner(rn)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4V-9alTU6bM"
      },
      "source": [
        "# load the model\n",
        "learn = learn.load('1D_ResNet152') # the model you want to load"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "l5JixxqvqAkB",
        "outputId": "57f79d44-aae6-4292-8fac-bd3acf7c8ae0"
      },
      "source": [
        "# get the classification matrix\n",
        "interp = ClassificationInterpretation.from_learner(learn) \n",
        "interp.plot_confusion_matrix(figsize=(20,20), dpi=60)\n",
        "plt.savefig('confusion_matrix.pdf',format='pdf')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4ee95f78a82a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get the classification matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minterp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassificationInterpretation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0minterp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'confusion_matrix.pdf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ClassificationInterpretation' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaKNQziY5ctc"
      },
      "source": [
        "# Bottleneck resnet: Loading the model for inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL1-FjR4jw3c"
      },
      "source": [
        "# load the model not for training but for making predictions (inference)\n",
        "learn_inf = load_learner('models/1D_ResNet152_fscore0.927867.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBUx_ZpNjw3d"
      },
      "source": [
        "# make prediction\n",
        "learn_inf.predict('images/grizzly.jpg') # image as example\n",
        "'''returned three things: the predicted category in the same format you originally provided \n",
        "(in this case, that’s a string), the index of the predicted category, and the probabilities of each category\n",
        "The last two are based on the order of categories in the vocab of the DataLoaders '''\n",
        "# check vocab\n",
        "learn_inf.dls.vocab"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}