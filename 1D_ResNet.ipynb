{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1D_ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UjbgfwgeYqfB",
        "b98f0GqJSm9Q",
        "1ZAOtjQ3W86-",
        "HsVIBweZPc_Q"
      ],
      "authorship_tag": "ABX9TyPeQ0fjMShdXpZPlYBeDCeF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lphohmann/DL_microbial_gene_classifier/blob/main/1D_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SAKcjsUe496"
      },
      "source": [
        "# to do:\n",
        "- look into different ResNet architectures: wide ResNets, xresnet, resnest, ..\n",
        "- bottleneck ResNet, try adding mixup callback as well\n",
        "- note: if the callback is something you only want during training, you should pass it into your fit function rather than the Learner -> pass mixup into fit\n",
        "\n",
        "\n",
        "- fix metric error: explore cause \n",
        "- fix confusion matrix to get a clear view of whats going on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6c9t37zYlS0"
      },
      "source": [
        "# Setting everything up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLoMrgCjYlS7"
      },
      "source": [
        "%%capture\n",
        "!pip install fastai --upgrade\n",
        "#!pip install -Uqq fastbook --upgrade\n",
        "#!pip install torchtext==0.8.1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFsoEIVWYlS8"
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from fastai import *\n",
        "from fastai.vision.all import *\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D118gfuuYlS9",
        "outputId": "6a31d4d4-8a97-4d54-e8bd-30f6ffbb2811"
      },
      "source": [
        "# mount google drive to access files and set the correct working\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd drive/MyDrive/ColabNotebooks/DL_project/\n",
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ColabNotebooks/DL_project\n",
            "/content/drive/MyDrive/ColabNotebooks/DL_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjbgfwgeYqfB"
      },
      "source": [
        "# Define functions required for creating the Datablock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWhRflf_YqfE"
      },
      "source": [
        "# defining functions required for building the DataBlock\n",
        "# one hot encoding function\n",
        "def OH_enc(seq: str):\n",
        "    # get the categories into array\n",
        "    cats = ['K', 'D', 'N', 'E', 'R', 'A', 'T', 'L', 'I', 'Q', 'C', 'F', 'G', 'W', 'M', 'S', 'H', 'P', 'V', 'Y']\n",
        "    cat_array = np.array(sorted(cats), ndmin=1) #\n",
        "    # get seq into array\n",
        "    trunc_seq = seq[:300] # truncate sequences longer than 300 \n",
        "    seq_array = np.array(list(trunc_seq))\n",
        "    #one hot encode the sequence\n",
        "    onehot_encoder = OneHotEncoder(categories=[cat_array],sparse=False,handle_unknown='ignore')\n",
        "    onehot_encoded_seq = onehot_encoder.fit_transform(seq_array.reshape(len(seq_array), 1))\n",
        "    return np.transpose(onehot_encoded_seq)\n",
        "\n",
        "# zero padding function\n",
        "def pad_along_axis(array: np.ndarray, target_length: int, axis: int = 0):\n",
        "    pad_size = target_length - array.shape[axis]\n",
        "    if pad_size <= 0:\n",
        "        return array\n",
        "    npad = [(0, 0)] * array.ndim\n",
        "    npad[axis] = (0, pad_size)\n",
        "    return np.pad(array, pad_width=npad, mode='constant', constant_values=0)\n",
        "\n",
        "# combine in one function\n",
        "def main_item_tfms(seq): # added -> None because the tensor shape later is 1,2820 and i think it should be 20,2820\n",
        "    enc_seq = OH_enc(seq)\n",
        "    pad_encseq_array = pad_along_axis(enc_seq,300,1)\n",
        "    return pad_encseq_array "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtRGsGMCY9Qq"
      },
      "source": [
        "# get_x and y by specifying column in dataframe\n",
        "def get_y(r): return r['Knum']\n",
        "def get_x(r): \n",
        "    return main_item_tfms(r['Seq']) # apply the one hot encoding and padding function"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsYPsgVGYqfH"
      },
      "source": [
        "# read in my data from which training and validation set will be created\n",
        "trainval = pd.read_csv('trainval.csv', low_memory=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F03yODg-YqfI"
      },
      "source": [
        "# CategoryBlock -> typetfm: categorize, batchtfm: CUDA, itemtfm: totensor\n",
        "def CategoryBlock(vocab=None, sort=True, add_na=False):\n",
        "    \"`TransformBlock` for single-label categorical targets\"\n",
        "    return TransformBlock(type_tfms=Categorize(vocab=vocab, sort=sort, add_na=add_na))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "M6S6U6GZYqfJ",
        "outputId": "bd9531b4-10b3-4e94-a146-e03f619c5d04"
      },
      "source": [
        "'''\n",
        "# building the datablock\n",
        "dblock = DataBlock(blocks=(TransformBlock(batch_tfms=IntToFloatTensor), CategoryBlock(vocab=['K00024', 'K00121', 'K00122', 'K00123', 'K00124', 'K00126',\n",
        "       'K00127', 'K00148', 'K00169', 'K00170', 'K00171', 'K00172',\n",
        "       'K00194', 'K00196', 'K00197', 'K00198', 'K00200', 'K00201',\n",
        "       'K00202', 'K00317', 'K00320', 'K00441', 'K00600', 'K00625',\n",
        "       'K00672', 'K00830', 'K00925', 'K01007', 'K01070', 'K01499',\n",
        "       'K01595', 'K01895', 'K03388', 'K03389', 'K03390', 'K05979',\n",
        "       'K06034', 'K08097', 'K08691', 'K08692', 'K09733', 'K10713',\n",
        "       'K10714', 'K11212', 'K11261', 'K11779', 'K11780', 'K12234',\n",
        "       'K13039', 'K13788', 'K14067', 'K14080', 'K14083', 'K14940',\n",
        "       'K14941', 'K15228', 'K15229', 'K18277'])),\n",
        "                 splitter = TrainTestSplitter(test_size=0.2, random_state=42, stratify=trainval[['Knum']]),\n",
        "                 get_x = get_x,\n",
        "                 get_y = get_y\n",
        "                 )\n",
        "'''"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# building the datablock\\ndblock = DataBlock(blocks=(TransformBlock(batch_tfms=IntToFloatTensor), CategoryBlock(vocab=['K00024', 'K00121', 'K00122', 'K00123', 'K00124', 'K00126',\\n       'K00127', 'K00148', 'K00169', 'K00170', 'K00171', 'K00172',\\n       'K00194', 'K00196', 'K00197', 'K00198', 'K00200', 'K00201',\\n       'K00202', 'K00317', 'K00320', 'K00441', 'K00600', 'K00625',\\n       'K00672', 'K00830', 'K00925', 'K01007', 'K01070', 'K01499',\\n       'K01595', 'K01895', 'K03388', 'K03389', 'K03390', 'K05979',\\n       'K06034', 'K08097', 'K08691', 'K08692', 'K09733', 'K10713',\\n       'K10714', 'K11212', 'K11261', 'K11779', 'K11780', 'K12234',\\n       'K13039', 'K13788', 'K14067', 'K14080', 'K14083', 'K14940',\\n       'K14941', 'K15228', 'K15229', 'K18277'])),\\n                 splitter = TrainTestSplitter(test_size=0.2, random_state=42, stratify=trainval[['Knum']]),\\n                 get_x = get_x,\\n                 get_y = get_y\\n                 )\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWuI9RzSlXwW"
      },
      "source": [
        "# alt block, not specifying categories\n",
        "# building the datablock\n",
        "dblock = DataBlock(blocks=(TransformBlock(batch_tfms=IntToFloatTensor), CategoryBlock()),\n",
        "                 splitter = TrainTestSplitter(test_size=0.2, random_state=42, stratify=trainval[['Knum']]),\n",
        "                 get_x = get_x,\n",
        "                 get_y = get_y\n",
        "                 )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9nXl6DvYqfL"
      },
      "source": [
        "#dblock.summary(trainval)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSd5LpFgZHXl"
      },
      "source": [
        "# Create the dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTESBqfOZHXm"
      },
      "source": [
        "# create dataloaders from datablock \n",
        "dls = dblock.dataloaders(trainval, bs=256, shuffle=True, drop_last=True) # shuffle the data to prevent overfitting due to an organized dataset and drop the last incomplete batch"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arZeSZlmZHXn"
      },
      "source": [
        "# visualize batch label distribution, compare with hist after balance correction\n",
        "x,y = dls.one_batch()\n",
        "#plt.hist(y,bins=dls.c) # if run with gpu there is a type error"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51xVxDwBZHXo"
      },
      "source": [
        "# access the dataset from datablock\n",
        "dsets = dblock.datasets(trainval)\n",
        "#dsets.train\n",
        "#dsets.valid"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmOwIMZ7DFS1"
      },
      "source": [
        "# label distribution in valid set\n",
        "valid_label_count = Counter(dsets.valid.items.Knum)\n",
        "valid_label_count.most_common() # check the distribution of seqs per label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcHmGZCeZHXq"
      },
      "source": [
        "# label distribution in valid set\n",
        "train_label_count = Counter(dsets.train.items.Knum)\n",
        "train_label_count.most_common() # check the distribution of seqs per label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8hMjO-zZHXq"
      },
      "source": [
        "# 1. calc weights for each label class\n",
        "class_weights = {} # empty dict to be filled with the class weights\n",
        "for label in train_label_count:\n",
        "    class_weights[label] = 1/train_label_count[label] # for every category the weight is (1 / number of associated sequences)\n",
        "wgts = dsets.train.items.Knum.map(class_weights).values[:len(dsets.train)] # [:len(dsets.train)] not needed\n",
        "weighted_dls = dblock.dataloaders(trainval,bs=256, dl_type=WeightedDL, wgts=wgts, shuffle=True, drop_last=True) \n",
        "dls.train = weighted_dls.train # replace the train dl with a weighted dl \n",
        "\n",
        "# note: check in which order /type weights have to be for the weighted dataloader --> can also check later if it works by looking at batch composition"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvXF_MDrZHXr",
        "outputId": "da3525b2-edbe-4aee-aa6e-b4c4f71ea793"
      },
      "source": [
        "# check dls attributes .c and .vocab\n",
        "#dls.vocab\n",
        "dls.c"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1qkot2mZHXt"
      },
      "source": [
        "# check one batch to make sure the dls is constructed right (balanced)\n",
        "x,y = dls.one_batch()\n",
        "#y # these should be the targets \n",
        "#x # and these the encoded sequences"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFE9ctjIZHXu",
        "outputId": "6c09ccc8-9b48-4856-fc4d-2245944b6aba"
      },
      "source": [
        "# check the shape\n",
        "x.shape #torch.Size([256, 20, 300])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 20, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQhoZsyKZHXv"
      },
      "source": [
        "# check the label distribution in the batch to see if balancing was successful (note:maybe do a before and after weighing the dataloader)\n",
        "#plt.hist(y,bins=dls.c)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b98f0GqJSm9Q"
      },
      "source": [
        "# Functions for the Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGZHTGu3_qWh"
      },
      "source": [
        "# the metric \n",
        "# choose one that is also fine for unbalanced datasets such as the F1score\n",
        "# a majority negative class, while labels not present in the data will result in 0 components in a macro average.\n",
        "F1Score = F1Score(labels=dls.vocab, average='macro') # 'macro' calculate score for each label individually, and then find their unweighted mean. penalizes poor performance on minority classes more\n",
        "# alt. RocAUC?"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQMX7EvvWDAQ"
      },
      "source": [
        "# callback to fix RuntimeError: Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same\n",
        "def cb(self): \n",
        "    new_xb = [x.type(torch.FloatTensor).cuda() for x in self.learn.xb]\n",
        "    self.learn.xb = new_xb\n",
        "    return self.learn.xb\n",
        "t_type = Callback(before_batch=cb)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHWEPnsBJBEC"
      },
      "source": [
        "# callback to save the model during training\n",
        "smc = SaveModelCallback(monitor=\"f1_score\", fname=\"1D_ResNet\", comp=np.greater, with_opt=True) # change comp based on metric; CHANGE NAME AS WELL TO CORRECTYL SAVE MDOEL"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um7w85KsmGpy"
      },
      "source": [
        "# callback to stop training when the model doesnt improve anymore\n",
        "estop = EarlyStoppingCallback(monitor=\"f1_score\", min_delta=0.001, comp=np.greater, patience=5) # change comp based on metric"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZAOtjQ3W86-"
      },
      "source": [
        "# Bottleneck resnet: Book-based architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCJ-vGmcXHvq"
      },
      "source": [
        "# the stem\n",
        "def _resnet_stem(*sizes): \n",
        "    return [\n",
        "        ConvLayer(sizes[i], sizes[i+1], 3, stride = 2, ndim=1 if i==0 else 1) for i in range(len(sizes)-1) # ndim\n",
        "    ] + [nn.MaxPool1d(kernel_size=3, stride=2, padding=1)] # 1d\n",
        "\n",
        "m = _resnet_stem(20,32,32,64) # just add 20, to add the first layer to increate to 20 channels"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk_K4o_ca13t"
      },
      "source": [
        "def _conv_block(ni,nf,stride): \n",
        "    return nn.Sequential(\n",
        "        ConvLayer(ni, nf//4, 1, ndim=1), # ndim\n",
        "        ConvLayer(nf//4, nf//4, stride=stride, ndim=1), #\n",
        "        ConvLayer(nf//4, nf, 1, act_cls=None, norm_type=NormType.BatchZero, ndim=1)) #\n",
        "\n",
        "class ResBlock(Module):\n",
        "    def __init__(self, ni, nf, stride=1):\n",
        "        self.convs = _conv_block(ni,nf,stride)\n",
        "        self.idconv = noop if ni==nf else ConvLayer(ni, nf, 1, act_cls=None, ndim=1) # ndim\n",
        "        self.pool = noop if stride==1 else nn.AvgPool1d(2, ceil_mode=True) # changed to 1d\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return F.relu(self.convs(x) + self.idconv(self.pool(x)))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDAPie5zXK7o"
      },
      "source": [
        "# putting it all together\n",
        "class ResNet(nn.Sequential):\n",
        "    def __init__(self, n_out, layers, expansion=1):\n",
        "        stem = _resnet_stem(20,32,32,64) # \n",
        "        self.block_szs = [64, 64, 128, 256, 512]\n",
        "        for i in range(1,5): self.block_szs[i] *= expansion \n",
        "        blocks = [self._make_layer(*o) for o in enumerate(layers)] \n",
        "        super().__init__(*stem, *blocks,\n",
        "                        nn.AdaptiveAvgPool1d(1), Flatten(), #1d\n",
        "                        nn.Linear(self.block_szs[-1], n_out))\n",
        "\n",
        "    def _make_layer(self, idx, n_layers): \n",
        "        stride = 1 if idx==0 else 2\n",
        "        ch_in,ch_out = self.block_szs[idx:idx+2] \n",
        "        return nn.Sequential(*[\n",
        "            ResBlock(ch_in if i==0 else ch_out, ch_out, stride if i==0 else 1)\n",
        "            for i in range(n_layers) \n",
        "        ])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iplifuzXWvq"
      },
      "source": [
        "def get_learner(m):\n",
        "    #return Learner(dls, m, loss_func=nn.CrossEntropyLoss(), metrics=accuracy).to_fp16()\n",
        "    return Learner(dls, m, loss_func=nn.CrossEntropyLoss(), opt_func=Adam, lr=defaults.lr, cbs=[t_type,smc], metrics=[accuracy,F1Score], model_dir='models') # splitter=None,"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsHI0okdXbKp"
      },
      "source": [
        "rn = ResNet(dls.c, [3,4,6,3], 4) # these group sizes make up a resnet50\n",
        "learn = get_learner(rn)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZyfo_X5XRof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e2cab05-e532-46d9-8f47-234c029e7fb1"
      },
      "source": [
        "learn.model"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (0): ConvLayer(\n",
              "    (0): Conv1d(20, 32, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
              "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (1): ConvLayer(\n",
              "    (0): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
              "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (2): ConvLayer(\n",
              "    (0): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
              "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (3): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (idconv): ConvLayer(\n",
              "        (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
              "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (idconv): ConvLayer(\n",
              "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
              "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (pool): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (idconv): ConvLayer(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
              "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (pool): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (idconv): ConvLayer(\n",
              "        (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
              "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (pool): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): ResBlock(\n",
              "      (convs): Sequential(\n",
              "        (0): ConvLayer(\n",
              "          (0): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (1): ConvLayer(\n",
              "          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU()\n",
              "        )\n",
              "        (2): ConvLayer(\n",
              "          (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
              "          (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (8): AdaptiveAvgPool1d(output_size=1)\n",
              "  (9): Flatten(full=False)\n",
              "  (10): Linear(in_features=2048, out_features=58, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86_qLySZX6ss"
      },
      "source": [
        "# Bottleneck resnet: Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "aSDIKhiIXzcm",
        "outputId": "ce6f8da2-b774-4b73-e5e8-070ae8fe60cd"
      },
      "source": [
        "# choose an adequate lr\n",
        "learn.lr_find(suggest_funcs=(minimum, steep, valley, slide)) "
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(minimum=0.0013182567432522773, steep=0.0030199517495930195, valley=0.00010964782268274575, slide=0.015848932787775993)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1RLtEGgX3xt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f7461436-40cf-4db1-fe63-046f1e4ce1db"
      },
      "source": [
        "# train \n",
        "epochs=3\n",
        "lr=0.00010964782268274575 # based on valley in lr_find \n",
        "learn.fit_one_cycle(epochs, lr) # appareantly some labels in y_test don't appear in y_pred and are never predicted. This messes with the weighted f-score.\n",
        "# UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
        "# seems as they say \"nor\" -> check on the labels, all of them should be present in the model. maybe dls.vocab doesnt work in F1Score()."
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.307068</td>\n",
              "      <td>1.933362</td>\n",
              "      <td>0.497867</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>09:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.411079</td>\n",
              "      <td>1.064794</td>\n",
              "      <td>0.710649</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>09:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.297633</td>\n",
              "      <td>0.931130</td>\n",
              "      <td>0.746223</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>09:37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with f1_score value: 0.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZR8mU1yojnr"
      },
      "source": [
        "# Bottleneck resnet: Confusion matrix and model loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbwphK9NvVhK"
      },
      "source": [
        "the confusion matrix always gives out errors either because of RAM overload or other things.\n",
        "Next approach is to try to create a smaller dl from a sample of the validation set and then construct the matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "l5JixxqvqAkB",
        "outputId": "6870b9c3-5f39-4765-d8ee-f39dae876933"
      },
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn) # RAM error\n",
        "interp.plot_confusion_matrix() #AssertionError: ==: 5562084 95898"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-615b2e0addda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minterp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassificationInterpretation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# RAM error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minterp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#AssertionError: ==: 5562084 95898\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/interpret.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(self, normalize, title, cmap, norm_dec, plot_txt, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;34m\"Plot the confusion matrix, with `title` and using `cmap`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# This function is mainly copied from the sklearn docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/interpret.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;34m\"Confusion matrix as an `np.ndarray`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mto_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36mflatten_check\u001b[0;34m(inp, targ)\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;34m\"Check that `out` and `targ` have the same number of elements and flatten them.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTensorBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m     \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastcore/test.py\u001b[0m in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;34m\"`test` that `a==b`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastcore/test.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m\"`assert` that `cmp(a,b)`; display inputs and `cname or cmp.__name__` if it fails\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: ==:\n4975936\n85792"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-V9o3H93RMG"
      },
      "source": [
        "# confusion matrix gives an out-of-RAM error so i try to specify a smaller dl\n",
        "small_dl = dls.valid\n",
        "interp = ClassificationInterpretation.from_learner(learn,dl=small_dl) \n",
        "# plot it\n",
        "interp.plot_confusion_matrix(figsize=) #AssertionError: ==: 5562084 95898"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBQkXjDK5Wa2"
      },
      "source": [
        "# also gives RAM error\n",
        "interp = ClassificationInterpretation.from_learner(learn) # TypeError: __init__() missing 1 required positional argument: 'losses'\n",
        "losses,idxs = interp.top_losses()\n",
        "len(dls.valid_ds)==len(losses)==len(idxs)\n",
        "interp.plot_confusion_matrix() #AssertionError: ==: 5562084 95898"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9BgdKxBrNCI"
      },
      "source": [
        "# monkey patch confusion matrix out-of-RAM error\n",
        "# https://forums.fast.ai/t/unable-to-plot-confusion-matrix/68115/10\n",
        "# https://forums.fast.ai/t/cannot-plot-confusion-matrix-in-colab-pro-out-of-ram-error-and-runtime-crashes/88813\n",
        "@classmethod\n",
        "def from_learner(cls, learn, ds_idx=1, dl=None, act=None):\n",
        "        \"Construct interpretation object from a learner\"\n",
        "        if dl is None: dl = learn.dls[ds_idx].new(shuffled=False, drop_last=False)\n",
        "        return cls(dl, *learn.get_preds(dl=dl, with_input=False, with_loss=True, with_decoded=True, act=None)) # set with_imputs to False\n",
        "\n",
        "Interpretation.from_learner = from_learner\n",
        "# later interp = ClassificationInterpretation.from_learner(learn) gives : TypeError: __init__() missing 1 required positional argument: 'losses'"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0OCk54stA3K"
      },
      "source": [
        "# alternative monkey patch attempt: doesnt work because the @classmethod decorator is the lost during patching\n",
        "@patch\n",
        "def from_learner(x: Interpretation,**kwargs):\n",
        "        \"Construct interpretation object from a learner\"\n",
        "        if dl is None: dl = learn.dls[ds_idx].new(shuffled=False, drop_last=False)\n",
        "        return cls(dl, *learn.get_preds(dl=dl, with_input=False, with_loss=True, with_decoded=True, act=None)) # set with_imputs to False"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaKNQziY5ctc"
      },
      "source": [
        "# Bottleneck resnet: Loading the model for inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4V-9alTU6bM"
      },
      "source": [
        "# load the model (is it possible to continue training?)\n",
        "learn = learn.load('1D_ResNet') \n",
        "# model summary print out\n",
        "# do lr_find again before continuing training?"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL1-FjR4jw3c"
      },
      "source": [
        "# load the model not for training but for making predictions (inference)\n",
        "learn_inf = load_learner(path/'modelname.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBUx_ZpNjw3d"
      },
      "source": [
        "# make prediction\n",
        "learn_inf.predict('images/grizzly.jpg') # image as example\n",
        "'''returned three things: the predicted category in the same format you originally provided \n",
        "(in this case, thats a string), the index of the predicted category, and the probabilities of each category\n",
        "The last two are based on the order of categories in the vocab of the DataLoaders '''\n",
        "# check vocab\n",
        "learn_inf.dls.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsVIBweZPc_Q"
      },
      "source": [
        "# Defining the architecture for a 1D CNN (not ResNet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt8JJUpTRM1Y"
      },
      "source": [
        "# ConvLayer creates a sequence of convolutional (ni to nf), ReLU (if use_activ) and norm_type layers\n",
        "def block(ni, nf): return ConvLayer(ni, nf, stride=2, ndim=1, ks=5)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBVw_3JARNqZ"
      },
      "source": [
        "def get_model():\n",
        "    return nn.Sequential(\n",
        "        block(20, 32), #how to handle this\n",
        "        block(32, 64),\n",
        "        block(64, 128),\n",
        "        block(128, 256),\n",
        "        nn.AdaptiveAvgPool1d(1),\n",
        "        Flatten(),\n",
        "        nn.Linear(256, 58)) "
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOh92tvgRQt8"
      },
      "source": [
        "# metric\n",
        "#precision = Precision(average='weighted') \n",
        "# Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters macro to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
        "# create learn object\n",
        "\n",
        "#learn = Learner(dls, get_model(), loss_func=nn.CrossEntropyLoss(), metrics=accuracy) # switched metric from accuracy to precision for assessing dataset balance"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJlROi3H2mcR",
        "outputId": "af3e022e-6ea5-445f-b03b-fdbba4489a5e"
      },
      "source": [
        "#learn.model"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): ConvLayer(\n",
              "    (0): Conv1d(20, 32, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (1): ConvLayer(\n",
              "    (0): Conv1d(32, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (2): ConvLayer(\n",
              "    (0): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (3): ConvLayer(\n",
              "    (0): Conv1d(128, 256, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (4): AdaptiveAvgPool1d(output_size=1)\n",
              "  (5): Flatten(full=False)\n",
              "  (6): Linear(in_features=256, out_features=58, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgF09XkmVsRn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "481b4f9a-c292-4b0d-99c8-f89f75243862"
      },
      "source": [
        "# try with cnn learner instead\n",
        "#learn = cnn_learner(dls, get_model(), loss_func=nn.CrossEntropyLoss(), pretrained = False, metrics = accuracy)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-f2171330e283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# try with cnn learner instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py\u001b[0m in \u001b[0;36mcnn_learner\u001b[0;34m(dls, arch, normalize, n_out, pretrained, config, loss_func, opt_func, lr, splitter, cbs, metrics, path, model_dir, wd, wd_bn_bias, train_bn, moms, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_out\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_cnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0msplitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py\u001b[0m in \u001b[0;36mcreate_cnn_model\u001b[0;34m(arch, n_out, pretrained, cut, n_in, init, custom_head, concat_pool, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;34m\"Create custom convnet architecture\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_default_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cut'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_head\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mnf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_features_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py\u001b[0m in \u001b[0;36mcreate_body\u001b[0;34m(arch, n_in, pretrained, cut)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m\"Cut off the body of a typically pretrained `arch` as determined by `cut`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0march\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0m_update_first_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m#cut = ifnone(cut, cnn_config(arch)['cut'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'pretrained'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Riq7JkzWRU-F"
      },
      "source": [
        "#learn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7AqO-LCRVbi"
      },
      "source": [
        "#learn.lr_find() # choose an adequate lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLkvmonACaI"
      },
      "source": [
        "#from fastai.callbacks import SaveModelCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZQh0fvERV53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "415745f3-3927-4ba9-c956-36841b9952e3"
      },
      "source": [
        "# fit and train \n",
        "epochs=1\n",
        "lr=0.1\n",
        "learn = learn.fit_one_cycle(epochs, lr) #callbacks=[SaveModelCallback(learn, every='epoch',  monitor='accuracy', name='saved_1D_net')]) # make training more stable with fit_one_cycle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.078036</td>\n",
              "      <td>0.079609</td>\n",
              "      <td>0.979353</td>\n",
              "      <td>12:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoWjtgH0boK0",
        "outputId": "47c607e4-ca13-41ce-95dd-11077034d576"
      },
      "source": [
        "#len(dls.train_ds)\n",
        "#type(learn) # it looks like after .fit the resulting learn object is of type None for some reason. \n",
        "# i think i have to pass a parameter when creating the learner so that some stats are saved to later build the confusion matrix\n",
        "#learn.dls\n",
        "learn.model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): ConvLayer(\n",
              "    (0): Conv1d(20, 32, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (1): ConvLayer(\n",
              "    (0): Conv1d(32, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (2): ConvLayer(\n",
              "    (0): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (3): ConvLayer(\n",
              "    (0): Conv1d(128, 256, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (4): AdaptiveAvgPool1d(output_size=1)\n",
              "  (5): Flatten(full=False)\n",
              "  (6): Linear(in_features=256, out_features=58, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_sLckAXPzbX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "ce9a1d72-2341-4cfa-c0fc-e05240e89f10"
      },
      "source": [
        "# confusion matrix\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "#interp.plot_confusion_matrix(figsize=(12,12), dpi=60)\n",
        "interp.most_confused(min_val=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='346' class='' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      92.27% [346/375 02:22<00:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDuZZNUxaHAV"
      },
      "source": [
        "# save the architecture and the parameters\n",
        "learn.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tokZOszxaTDT"
      },
      "source": [
        "# check that the file exists\n",
        "path = Path()\n",
        "path.ls(file_exts='.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCx0vtzwaX0E"
      },
      "source": [
        "# load the model not for training but for making predictions (inference)\n",
        "learn_inf = load_learner(path/'export.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUxQmrbhalet"
      },
      "source": [
        "# make prediction\n",
        "learn_inf.predict('images/grizzly.jpg') # image as example\n",
        "'''returned three things: the predicted category in the same format you originally provided \n",
        "(in this case, thats a string), the index of the predicted category, and the probabilities of each category\n",
        "The last two are based on the order of categories in the vocab of the DataLoaders '''\n",
        "# check vocab\n",
        "learn_inf.dls.vocab\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}