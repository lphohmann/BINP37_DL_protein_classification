{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1D_ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "x0xWfZtSrWj2",
        "HsVIBweZPc_Q",
        "KrFpfhh9KDtY",
        "790lXw9baKRc"
      ],
      "authorship_tag": "ABX9TyPWe3HD/3sOjTCekaXvfMsh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lphohmann/DL_microbial_gene_classifier/blob/main/1D_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNOs9h03HA0w"
      },
      "source": [
        "# 1. Setting everything up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQFnDp2fo-H_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed86eaa-5422-47b8-f961-ac1c078f7c65"
      },
      "source": [
        "#hide\n",
        "!pip install fastai --upgrade\n",
        "#!pip install -Uqq fastbook --upgrade\n",
        "#!pip install torchtext==0.8.1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/ca/bc9f4e04adcdfda1357f5c63bc67a7bf4f315883ca544726f3376b1ed068/fastai-2.4-py3-none-any.whl (187kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 15.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 20kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 30kB 10.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 61kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 71kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 81kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 92kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 102kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 112kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 122kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 133kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 143kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 153kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 163kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 174kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 184kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: torch<1.10,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.9.0+cu102)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (19.3.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.10.0+cu102)\n",
            "Collecting fastcore<1.4,>=1.3.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b0/f1fbf554e0bf3c76e1bdc3b82eedfe41fcf656479586be38c64421082b1b/fastcore-1.3.20-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from fastprogress>=0.2.4->fastai) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.10,>=1.7.0->fastai) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->fastai) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (4.5.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.4.1)\n",
            "Installing collected packages: fastcore, fastai\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "Successfully installed fastai-2.4 fastcore-1.3.20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E-3B33Y5x84"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT3j2jdYk2gy"
      },
      "source": [
        "#hide\n",
        "#import fastbook\n",
        "#fastbook.setup_book()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFzbFyx1k3Q7"
      },
      "source": [
        "#hide\n",
        "#import fastai\n",
        "from fastai import *\n",
        "from fastai.vision.all import *\n",
        "#from fastai.text.all import *\n",
        "#from fastai.callback import *"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pvbcIQBeiBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be40527-bd13-4147-83fc-fb4b2fcc644a"
      },
      "source": [
        "# mount google drive to access files and set the correct working\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd drive/MyDrive/ColabNotebooks/DL_project/\n",
        "!pwd"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ColabNotebooks/DL_project\n",
            "/content/drive/MyDrive/ColabNotebooks/DL_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0xWfZtSrWj2"
      },
      "source": [
        "# Define functions required for creating the Datablock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxYlGka0tODh"
      },
      "source": [
        "# get the training and validation datasets"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Guo00Z6aDNiE"
      },
      "source": [
        "# defining functions required for building the DataBlock\n",
        "# one hot encoding function\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def OH_enc(seq: str):\n",
        "    # get the categories into array\n",
        "    cats = ['K', 'D', 'N', 'E', 'R', 'A', 'T', 'L', 'I', 'Q', 'C', 'F', 'G', 'W', 'M', 'S', 'H', 'P', 'V', 'Y']\n",
        "    cat_array = np.array(sorted(cats), ndmin=1) #\n",
        "    # get seq into array\n",
        "    trunc_seq = seq[:300] # truncate sequences longer than 300 \n",
        "    seq_array = np.array(list(trunc_seq))\n",
        "    #one hot encode the sequence\n",
        "    onehot_encoder = OneHotEncoder(categories=[cat_array],sparse=False,handle_unknown='ignore')\n",
        "    onehot_encoded_seq = onehot_encoder.fit_transform(seq_array.reshape(len(seq_array), 1))\n",
        "    return np.transpose(onehot_encoded_seq)\n",
        "\n",
        "# zero padding function\n",
        "def pad_along_axis(array: np.ndarray, target_length: int, axis: int = 0):\n",
        "    pad_size = target_length - array.shape[axis]\n",
        "    if pad_size <= 0:\n",
        "        return array\n",
        "    npad = [(0, 0)] * array.ndim\n",
        "    npad[axis] = (0, pad_size)\n",
        "    return np.pad(array, pad_width=npad, mode='constant', constant_values=0)\n",
        "\n",
        "# combine in one function\n",
        "def main_item_tfms(seq): # added -> None because the tensor shape later is 1,2820 and i think it should be 20,2820\n",
        "    enc_seq = OH_enc(seq)\n",
        "    pad_encseq_array = pad_along_axis(enc_seq,300,1)\n",
        "    return pad_encseq_array "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpO8YNjp4SUv"
      },
      "source": [
        "# get_x and y by specifying column in dataframe\n",
        "def get_y(r): return r['Knum']\n",
        "def get_x(r): \n",
        "    return main_item_tfms(r['Seq']) # apply the one hot encoding and padding function"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC97n5teDZiG"
      },
      "source": [
        "# read in my data from which training and validation set will be created\n",
        "trainval = pd.read_csv('trainval.csv', low_memory=False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwCPlBdOznAz"
      },
      "source": [
        "# CategoryBlock -> typetfm: categorize, batchtfm: CUDA, itemtfm: totensor\n",
        "def CategoryBlock(vocab=None, sort=True, add_na=False):\n",
        "    \"`TransformBlock` for single-label categorical targets\"\n",
        "    return TransformBlock(type_tfms=Categorize(vocab=vocab, sort=sort, add_na=add_na))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvFA5HinvFns"
      },
      "source": [
        "# alternative DataBlock try\n",
        "# building the datablock\n",
        "dblock = DataBlock(blocks=(TransformBlock(batch_tfms=IntToFloatTensor), CategoryBlock(vocab=['K00024', 'K00121', 'K00122', 'K00123', 'K00124', 'K00126',\n",
        "       'K00127', 'K00148', 'K00169', 'K00170', 'K00171', 'K00172',\n",
        "       'K00194', 'K00196', 'K00197', 'K00198', 'K00200', 'K00201',\n",
        "       'K00202', 'K00317', 'K00320', 'K00441', 'K00600', 'K00625',\n",
        "       'K00672', 'K00830', 'K00925', 'K01007', 'K01070', 'K01499',\n",
        "       'K01595', 'K01895', 'K03388', 'K03389', 'K03390', 'K05979',\n",
        "       'K06034', 'K08097', 'K08691', 'K08692', 'K09733', 'K10713',\n",
        "       'K10714', 'K11212', 'K11261', 'K11779', 'K11780', 'K12234',\n",
        "       'K13039', 'K13788', 'K14067', 'K14080', 'K14083', 'K14940',\n",
        "       'K14941', 'K15228', 'K15229', 'K18277'])),\n",
        "                 splitter = TrainTestSplitter(test_size=0.2, random_state=42, stratify=trainval[['Knum']]),\n",
        "                 get_x = get_x,\n",
        "                 get_y = get_y\n",
        "                 )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUxNCw2kvrsq"
      },
      "source": [
        "#dblock.summary(trainval)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ3rltkKJRMO"
      },
      "source": [
        "# Create the dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz27HTxgLIBi"
      },
      "source": [
        "# create dataloaders from datablock \n",
        "dls = dblock.dataloaders(trainval, bs=256, shuffle=True, drop_last=True) # shuffle the data to prevent overfitting due to an organized dataset and drop the last incomplete batch"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lefVyPCAuRkF"
      },
      "source": [
        "# access the dataset from datablock\n",
        "dsets = dblock.datasets(trainval)\n",
        "#dsets.train\n",
        "#dsets.valid"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d772GYXZ5cbF"
      },
      "source": [
        "from collections import Counter\n",
        "label_count = Counter(dsets.train.items.Knum)\n",
        "#label_count.most_common() # check the distribution of seqs per label"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUx81Al_8wX5"
      },
      "source": [
        "# 1. calc weights for each label class\n",
        "class_weights = {} # empty dict to be filled with the class weights\n",
        "for label in label_count:\n",
        "    class_weights[label] = 1/label_count[label] # for every category the weight is (1 / number of associated sequences)\n",
        "wgts = dsets.train.items.Knum.map(class_weights).values #[:len(dsets.train)] \n",
        "\n",
        "# check in which order /type weights have to be for the weighted dataloader --> can also check later if it works by looking at batch composition\n",
        "\n",
        "# my case\n",
        "weighted_dls = dblock.dataloaders(trainval,bs=256, dl_type=WeightedDL, wgts=wgts, shuffle=True, drop_last=True) \n",
        "dls.train = weighted_dls.train # replace the train dl with a weighted dl -> comment out before and after histogram visualizing to get comparison"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCZwWA5vCVzb",
        "outputId": "4a62380d-5aee-451c-f6c2-e0a79a795163"
      },
      "source": [
        "# check vocab of the dls \n",
        "dls.vocab"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['K00024', 'K00121', 'K00122', 'K00123', 'K00124', 'K00126', 'K00127', 'K00148', 'K00169', 'K00170', 'K00171', 'K00172', 'K00194', 'K00196', 'K00197', 'K00198', 'K00200', 'K00201', 'K00202', 'K00317', 'K00320', 'K00441', 'K00600', 'K00625', 'K00672', 'K00830', 'K00925', 'K01007', 'K01070', 'K01499', 'K01595', 'K01895', 'K03388', 'K03389', 'K03390', 'K05979', 'K06034', 'K08097', 'K08691', 'K08692', 'K09733', 'K10713', 'K10714', 'K11212', 'K11261', 'K11779', 'K11780', 'K12234', 'K13039', 'K13788', 'K14067', 'K14080', 'K14083', 'K14940', 'K14941', 'K15228', 'K15229', 'K18277']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV_uBmDOLKyo"
      },
      "source": [
        "# check one batch to make sure the dls is constructed right\n",
        "x,y = dls.one_batch()\n",
        "#y # these should be the targets \n",
        "#x # and these the encoded sequences"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9rClUPdWTGd",
        "outputId": "087524a2-038d-46cf-a61e-d661799e205b"
      },
      "source": [
        "# check the shape\n",
        "x.shape #torch.Size([256, 20, 300])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 20, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "K7mdK9hiSXB9",
        "outputId": "43e908c0-48f7-40b2-83dd-7fc3dfc26a29"
      },
      "source": [
        "# check the label distribution in the batch to see if balancing was successful (note:maybe do a before and after weighing the dataloader)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(y,bins=58)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 5.,  2.,  5.,  2.,  2.,  3.,  3.,  4.,  5.,  7.,  4.,  4.,  6.,\n",
              "         6.,  2.,  5.,  3.,  2.,  3.,  8.,  6.,  5.,  2., 10.,  3.,  5.,\n",
              "         3.,  7.,  2.,  1.,  4.,  1.,  6.,  8.,  7.,  5.,  7.,  5.,  2.,\n",
              "         3.,  4.,  5.,  6., 13.,  4.,  5.,  4.,  6.,  5.,  2.,  0.,  4.,\n",
              "         6.,  3.,  4.,  3.,  5.,  4.]),\n",
              " array([ 0.        ,  0.98275862,  1.96551724,  2.94827586,  3.93103448,\n",
              "         4.9137931 ,  5.89655172,  6.87931034,  7.86206897,  8.84482759,\n",
              "         9.82758621, 10.81034483, 11.79310345, 12.77586207, 13.75862069,\n",
              "        14.74137931, 15.72413793, 16.70689655, 17.68965517, 18.67241379,\n",
              "        19.65517241, 20.63793103, 21.62068966, 22.60344828, 23.5862069 ,\n",
              "        24.56896552, 25.55172414, 26.53448276, 27.51724138, 28.5       ,\n",
              "        29.48275862, 30.46551724, 31.44827586, 32.43103448, 33.4137931 ,\n",
              "        34.39655172, 35.37931034, 36.36206897, 37.34482759, 38.32758621,\n",
              "        39.31034483, 40.29310345, 41.27586207, 42.25862069, 43.24137931,\n",
              "        44.22413793, 45.20689655, 46.18965517, 47.17241379, 48.15517241,\n",
              "        49.13793103, 50.12068966, 51.10344828, 52.0862069 , 53.06896552,\n",
              "        54.05172414, 55.03448276, 56.01724138, 57.        ]),\n",
              " <a list of 58 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsVIBweZPc_Q"
      },
      "source": [
        "# Defining the architecture for a 1D CNN (not ResNet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RKh1iiexzq0"
      },
      "source": [
        "# monkey patch to change back tensor type\n",
        "def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):\n",
        "    input= input.type(torch.FloatTensor).cuda() # added this line to change the tensor type\n",
        "    if self.padding_mode != 'zeros':\n",
        "        return F.conv1d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
        "                        weight, bias, self.stride,\n",
        "                        _single(0), self.dilation, self.groups)\n",
        "    return F.conv1d(input, weight, bias, self.stride,\n",
        "                    self.padding, self.dilation, self.groups)\n",
        "# replace in the module\n",
        "nn.Conv1d._conv_forward = _conv_forward"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt8JJUpTRM1Y"
      },
      "source": [
        "# ConvLayer creates a sequence of convolutional (ni to nf), ReLU (if use_activ) and norm_type layers\n",
        "def block(ni, nf): return ConvLayer(ni, nf, stride=2, ndim=1, ks=5)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBVw_3JARNqZ"
      },
      "source": [
        "def get_model():\n",
        "    return nn.Sequential(\n",
        "        block(20, 32), #how to handle this\n",
        "        block(32, 64),\n",
        "        block(64, 128),\n",
        "        block(128, 256),\n",
        "        nn.AdaptiveAvgPool1d(1),\n",
        "        Flatten(),\n",
        "        nn.Linear(256, 58)) "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOh92tvgRQt8"
      },
      "source": [
        "# metric\n",
        "#precision = Precision(average='weighted') \n",
        "# Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
        "# create learn object\n",
        "\n",
        "#learn = Learner(dls, get_model(), loss_func=nn.CrossEntropyLoss(), metrics=accuracy) # switched metric from accuracy to precision for assessing dataset balance"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgF09XkmVsRn"
      },
      "source": [
        "# try with cnn learner instead\n",
        "#learn = cnn_learner(dls, get_model(), loss_func=nn.CrossEntropyLoss(), pretrained = False, metrics = accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Riq7JkzWRU-F"
      },
      "source": [
        "#learn.summary()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFMD8T5gXsGE"
      },
      "source": [
        "# in this cell i try to balance the training batches\n",
        "# import\n",
        "#from torch.utils.data.sampler import WeightedRandomSampler\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrFpfhh9KDtY"
      },
      "source": [
        "# Training the 1D CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7AqO-LCRVbi"
      },
      "source": [
        "#learn.lr_find() # choose an adequate lr"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLkvmonACaI"
      },
      "source": [
        "#from fastai.callbacks import SaveModelCallback"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZQh0fvERV53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "415745f3-3927-4ba9-c956-36841b9952e3"
      },
      "source": [
        "# fit and train \n",
        "epochs=1\n",
        "lr=0.1\n",
        "learn = learn.fit_one_cycle(epochs, lr) #callbacks=[SaveModelCallback(learn, every='epoch',  monitor='accuracy', name='saved_1D_net')]) # make training more stable with fit_one_cycle"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.078036</td>\n",
              "      <td>0.079609</td>\n",
              "      <td>0.979353</td>\n",
              "      <td>12:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoWjtgH0boK0",
        "outputId": "47c607e4-ca13-41ce-95dd-11077034d576"
      },
      "source": [
        "#len(dls.train_ds)\n",
        "#type(learn) # it looks like after .fit the resulting learn object is of type None for some reason. \n",
        "# i think i have to pass a parameter when creating the learner so that some stats are saved to later build the confusion matrix\n",
        "#learn.dls\n",
        "learn.model"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): ConvLayer(\n",
              "    (0): Conv1d(20, 32, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (1): ConvLayer(\n",
              "    (0): Conv1d(32, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (2): ConvLayer(\n",
              "    (0): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (3): ConvLayer(\n",
              "    (0): Conv1d(128, 256, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (4): AdaptiveAvgPool1d(output_size=1)\n",
              "  (5): Flatten(full=False)\n",
              "  (6): Linear(in_features=256, out_features=58, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_sLckAXPzbX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "ce9a1d72-2341-4cfa-c0fc-e05240e89f10"
      },
      "source": [
        "# confusion matrix\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "#interp.plot_confusion_matrix(figsize=(12,12), dpi=60)\n",
        "interp.most_confused(min_val=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='346' class='' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      92.27% [346/375 02:22<00:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "790lXw9baKRc"
      },
      "source": [
        "# Saving the 1D CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDuZZNUxaHAV"
      },
      "source": [
        "# save the architecture and the parameters\n",
        "learn.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tokZOszxaTDT"
      },
      "source": [
        "# check that the file exists\n",
        "path = Path()\n",
        "path.ls(file_exts='.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCx0vtzwaX0E"
      },
      "source": [
        "# load the model not for training but for making predictions (inference)\n",
        "learn_inf = load_learner(path/'export.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUxQmrbhalet"
      },
      "source": [
        "# make prediction\n",
        "learn_inf.predict('images/grizzly.jpg') # image as example\n",
        "'''returned three things: the predicted category in the same format you originally provided \n",
        "(in this case, that’s a string), the index of the predicted category, and the probabilities of each category\n",
        "The last two are based on the order of categories in the vocab of the DataLoaders '''\n",
        "# check vocab\n",
        "learn_inf.dls.vocab\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}