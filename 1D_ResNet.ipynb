{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1D_ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "x0xWfZtSrWj2",
        "HsVIBweZPc_Q",
        "KrFpfhh9KDtY",
        "790lXw9baKRc"
      ],
      "authorship_tag": "ABX9TyMVKT822Y/Hhm+SaCzAuX1G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lphohmann/DL_microbial_gene_classifier/blob/main/1D_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SAKcjsUe496"
      },
      "source": [
        "# to do:\n",
        "- define the resnet architecture, not sure if avaiable with 1D convolution\n",
        "- look into different ResNet architectures: wide ResNets, xresnet, resnest, ..\n",
        "- either 1D ResNet or 2D ResNet (copy the channels to get 3 or add a layer to the network input that does that in forward pass)\n",
        "- try to change the prebuilt 2D resnet architecture from fastai with 1d conv layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNOs9h03HA0w"
      },
      "source": [
        "# Setting everything up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQFnDp2fo-H_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a24f6536-1678-4bff-dbc3-c0ecba7e4322"
      },
      "source": [
        "#hide\n",
        "!pip install fastai --upgrade\n",
        "#!pip install -Uqq fastbook --upgrade\n",
        "#!pip install torchtext==0.8.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/ca/bc9f4e04adcdfda1357f5c63bc67a7bf4f315883ca544726f3376b1ed068/fastai-2.4-py3-none-any.whl (187kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 14.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 20kB 18.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 30kB 20.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 40kB 22.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 51kB 24.7MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 61kB 25.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 71kB 27.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 81kB 27.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 92kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 102kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 112kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 122kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 133kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 143kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 153kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 163kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 174kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 184kB 28.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 28.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.10.0+cu102)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: torch<1.10,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.9.0+cu102)\n",
            "Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (19.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n",
            "Collecting fastcore<1.4,>=1.3.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b0/f1fbf554e0bf3c76e1bdc3b82eedfe41fcf656479586be38c64421082b1b/fastcore-1.3.20-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.10,>=1.7.0->fastai) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->fastai) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (4.5.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.4.1)\n",
            "Installing collected packages: fastcore, fastai\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "Successfully installed fastai-2.4 fastcore-1.3.20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E-3B33Y5x84"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT3j2jdYk2gy"
      },
      "source": [
        "#hide\n",
        "#import fastbook\n",
        "#fastbook.setup_book()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFzbFyx1k3Q7"
      },
      "source": [
        "#hide\n",
        "#import fastai\n",
        "from fastai import *\n",
        "from fastai.vision.all import *\n",
        "#from fastai.text.all import *\n",
        "#from fastai.callback import *"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pvbcIQBeiBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63eb7edd-f4bd-4fdd-f08c-be385dbb5334"
      },
      "source": [
        "# mount google drive to access files and set the correct working\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd drive/MyDrive/ColabNotebooks/DL_project/\n",
        "!pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ColabNotebooks/DL_project\n",
            "/content/drive/MyDrive/ColabNotebooks/DL_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0xWfZtSrWj2"
      },
      "source": [
        "# Define functions required for creating the Datablock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxYlGka0tODh"
      },
      "source": [
        "# get the training and validation datasets"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Guo00Z6aDNiE"
      },
      "source": [
        "# defining functions required for building the DataBlock\n",
        "# one hot encoding function\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def OH_enc(seq: str):\n",
        "    # get the categories into array\n",
        "    cats = ['K', 'D', 'N', 'E', 'R', 'A', 'T', 'L', 'I', 'Q', 'C', 'F', 'G', 'W', 'M', 'S', 'H', 'P', 'V', 'Y']\n",
        "    cat_array = np.array(sorted(cats), ndmin=1) #\n",
        "    # get seq into array\n",
        "    trunc_seq = seq[:300] # truncate sequences longer than 300 \n",
        "    seq_array = np.array(list(trunc_seq))\n",
        "    #one hot encode the sequence\n",
        "    onehot_encoder = OneHotEncoder(categories=[cat_array],sparse=False,handle_unknown='ignore')\n",
        "    onehot_encoded_seq = onehot_encoder.fit_transform(seq_array.reshape(len(seq_array), 1))\n",
        "    return np.transpose(onehot_encoded_seq)\n",
        "\n",
        "# zero padding function\n",
        "def pad_along_axis(array: np.ndarray, target_length: int, axis: int = 0):\n",
        "    pad_size = target_length - array.shape[axis]\n",
        "    if pad_size <= 0:\n",
        "        return array\n",
        "    npad = [(0, 0)] * array.ndim\n",
        "    npad[axis] = (0, pad_size)\n",
        "    return np.pad(array, pad_width=npad, mode='constant', constant_values=0)\n",
        "\n",
        "# combine in one function\n",
        "def main_item_tfms(seq): # added -> None because the tensor shape later is 1,2820 and i think it should be 20,2820\n",
        "    enc_seq = OH_enc(seq)\n",
        "    pad_encseq_array = pad_along_axis(enc_seq,300,1)\n",
        "    return pad_encseq_array "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpO8YNjp4SUv"
      },
      "source": [
        "# get_x and y by specifying column in dataframe\n",
        "def get_y(r): return r['Knum']\n",
        "def get_x(r): \n",
        "    return main_item_tfms(r['Seq']) # apply the one hot encoding and padding function"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC97n5teDZiG"
      },
      "source": [
        "# read in my data from which training and validation set will be created\n",
        "trainval = pd.read_csv('trainval.csv', low_memory=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwCPlBdOznAz"
      },
      "source": [
        "# CategoryBlock -> typetfm: categorize, batchtfm: CUDA, itemtfm: totensor\n",
        "def CategoryBlock(vocab=None, sort=True, add_na=False):\n",
        "    \"`TransformBlock` for single-label categorical targets\"\n",
        "    return TransformBlock(type_tfms=Categorize(vocab=vocab, sort=sort, add_na=add_na))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvFA5HinvFns"
      },
      "source": [
        "# alternative DataBlock try\n",
        "# building the datablock\n",
        "dblock = DataBlock(blocks=(TransformBlock(batch_tfms=IntToFloatTensor), CategoryBlock(vocab=['K00024', 'K00121', 'K00122', 'K00123', 'K00124', 'K00126',\n",
        "       'K00127', 'K00148', 'K00169', 'K00170', 'K00171', 'K00172',\n",
        "       'K00194', 'K00196', 'K00197', 'K00198', 'K00200', 'K00201',\n",
        "       'K00202', 'K00317', 'K00320', 'K00441', 'K00600', 'K00625',\n",
        "       'K00672', 'K00830', 'K00925', 'K01007', 'K01070', 'K01499',\n",
        "       'K01595', 'K01895', 'K03388', 'K03389', 'K03390', 'K05979',\n",
        "       'K06034', 'K08097', 'K08691', 'K08692', 'K09733', 'K10713',\n",
        "       'K10714', 'K11212', 'K11261', 'K11779', 'K11780', 'K12234',\n",
        "       'K13039', 'K13788', 'K14067', 'K14080', 'K14083', 'K14940',\n",
        "       'K14941', 'K15228', 'K15229', 'K18277'])),\n",
        "                 splitter = TrainTestSplitter(test_size=0.2, random_state=42, stratify=trainval[['Knum']]),\n",
        "                 get_x = get_x,\n",
        "                 get_y = get_y\n",
        "                 )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUxNCw2kvrsq"
      },
      "source": [
        "#dblock.summary(trainval)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ3rltkKJRMO"
      },
      "source": [
        "# Create the dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz27HTxgLIBi"
      },
      "source": [
        "# create dataloaders from datablock \n",
        "dls = dblock.dataloaders(trainval, bs=256, shuffle=True, drop_last=True) # shuffle the data to prevent overfitting due to an organized dataset and drop the last incomplete batch"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "4yA2Jp-0afhb",
        "outputId": "80b224b8-33b0-4a3b-da56-731c66923093"
      },
      "source": [
        "# visualize batch label distribution, compare with hist after balance correction\n",
        "x,y = dls.one_batch()\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(y,bins=dls.c)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([10., 10.,  7., 14.,  3.,  0.,  4.,  2.,  2.,  2.,  0.,  0.,  1.,\n",
              "         0.,  0.,  0.,  1.,  2.,  0.,  4.,  2.,  3., 12., 12.,  1., 12.,\n",
              "        11.,  3.,  4.,  2., 23., 44.,  4.,  1.,  1.,  1.,  3.,  1.,  1.,\n",
              "         3.,  1.,  1.,  0.,  2.,  1., 10.,  0.,  7.,  2.,  2.,  5.,  0.,\n",
              "         9.,  0.,  1.,  0.,  2.,  7.]),\n",
              " array([ 0.        ,  0.98275862,  1.96551724,  2.94827586,  3.93103448,\n",
              "         4.9137931 ,  5.89655172,  6.87931034,  7.86206897,  8.84482759,\n",
              "         9.82758621, 10.81034483, 11.79310345, 12.77586207, 13.75862069,\n",
              "        14.74137931, 15.72413793, 16.70689655, 17.68965517, 18.67241379,\n",
              "        19.65517241, 20.63793103, 21.62068966, 22.60344828, 23.5862069 ,\n",
              "        24.56896552, 25.55172414, 26.53448276, 27.51724138, 28.5       ,\n",
              "        29.48275862, 30.46551724, 31.44827586, 32.43103448, 33.4137931 ,\n",
              "        34.39655172, 35.37931034, 36.36206897, 37.34482759, 38.32758621,\n",
              "        39.31034483, 40.29310345, 41.27586207, 42.25862069, 43.24137931,\n",
              "        44.22413793, 45.20689655, 46.18965517, 47.17241379, 48.15517241,\n",
              "        49.13793103, 50.12068966, 51.10344828, 52.0862069 , 53.06896552,\n",
              "        54.05172414, 55.03448276, 56.01724138, 57.        ]),\n",
              " <a list of 58 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lefVyPCAuRkF"
      },
      "source": [
        "# access the dataset from datablock\n",
        "dsets = dblock.datasets(trainval)\n",
        "#dsets.train\n",
        "#dsets.valid"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d772GYXZ5cbF"
      },
      "source": [
        "from collections import Counter\n",
        "label_count = Counter(dsets.train.items.Knum)\n",
        "#label_count.most_common() # check the distribution of seqs per label"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUx81Al_8wX5"
      },
      "source": [
        "# 1. calc weights for each label class\n",
        "class_weights = {} # empty dict to be filled with the class weights\n",
        "for label in label_count:\n",
        "    class_weights[label] = 1/label_count[label] # for every category the weight is (1 / number of associated sequences)\n",
        "wgts = dsets.train.items.Knum.map(class_weights).values #[:len(dsets.train)] \n",
        "\n",
        "# check in which order /type weights have to be for the weighted dataloader --> can also check later if it works by looking at batch composition\n",
        "\n",
        "# my case\n",
        "weighted_dls = dblock.dataloaders(trainval,bs=256, dl_type=WeightedDL, wgts=wgts, shuffle=True, drop_last=True) \n",
        "dls.train = weighted_dls.train # replace the train dl with a weighted dl -> comment out before and after histogram visualizing to get comparison"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCZwWA5vCVzb",
        "outputId": "e37d37e1-5d60-49b2-9577-92f43ce871d5"
      },
      "source": [
        "# check vocab of the dls \n",
        "#dls.vocab\n",
        "dls.c"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV_uBmDOLKyo"
      },
      "source": [
        "# check one batch to make sure the dls is constructed right\n",
        "x,y = dls.one_batch()\n",
        "#y # these should be the targets \n",
        "#x # and these the encoded sequences"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9rClUPdWTGd",
        "outputId": "5bd95a15-c7f8-44bb-c3ca-8f8bd9640ffc"
      },
      "source": [
        "# check the shape\n",
        "x.shape #torch.Size([256, 20, 300])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 20, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "K7mdK9hiSXB9",
        "outputId": "bd1c2ae3-dc1e-44e4-9a04-0673dca7f54f"
      },
      "source": [
        "# check the label distribution in the batch to see if balancing was successful (note:maybe do a before and after weighing the dataloader)\n",
        "#import matplotlib.pyplot as plt\n",
        "plt.hist(y,bins=dls.c)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 2.,  7.,  3.,  2.,  4.,  5.,  5.,  3.,  4.,  3.,  7.,  4.,  5.,\n",
              "         1.,  2.,  4.,  6.,  3.,  6.,  5.,  2.,  4.,  7.,  5.,  1.,  7.,\n",
              "         9.,  2.,  3.,  4.,  2.,  6.,  2.,  2.,  6.,  3.,  5.,  3.,  7.,\n",
              "         5.,  4.,  3.,  5., 11.,  1.,  5.,  6.,  4.,  5., 11.,  2.,  4.,\n",
              "         4.,  4.,  4.,  7.,  4.,  6.]),\n",
              " array([ 0.        ,  0.98275862,  1.96551724,  2.94827586,  3.93103448,\n",
              "         4.9137931 ,  5.89655172,  6.87931034,  7.86206897,  8.84482759,\n",
              "         9.82758621, 10.81034483, 11.79310345, 12.77586207, 13.75862069,\n",
              "        14.74137931, 15.72413793, 16.70689655, 17.68965517, 18.67241379,\n",
              "        19.65517241, 20.63793103, 21.62068966, 22.60344828, 23.5862069 ,\n",
              "        24.56896552, 25.55172414, 26.53448276, 27.51724138, 28.5       ,\n",
              "        29.48275862, 30.46551724, 31.44827586, 32.43103448, 33.4137931 ,\n",
              "        34.39655172, 35.37931034, 36.36206897, 37.34482759, 38.32758621,\n",
              "        39.31034483, 40.29310345, 41.27586207, 42.25862069, 43.24137931,\n",
              "        44.22413793, 45.20689655, 46.18965517, 47.17241379, 48.15517241,\n",
              "        49.13793103, 50.12068966, 51.10344828, 52.0862069 , 53.06896552,\n",
              "        54.05172414, 55.03448276, 56.01724138, 57.        ]),\n",
              " <a list of 58 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsVIBweZPc_Q"
      },
      "source": [
        "# Defining the architecture for a 1D CNN (not ResNet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RKh1iiexzq0"
      },
      "source": [
        "# monkey patch to change back tensor type\n",
        "def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):\n",
        "    input= input.type(torch.FloatTensor).cuda() # added this line to change the tensor type\n",
        "    if self.padding_mode != 'zeros':\n",
        "        return F.conv1d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
        "                        weight, bias, self.stride,\n",
        "                        _single(0), self.dilation, self.groups)\n",
        "    return F.conv1d(input, weight, bias, self.stride,\n",
        "                    self.padding, self.dilation, self.groups)\n",
        "# replace in the module\n",
        "nn.Conv1d._conv_forward = _conv_forward"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt8JJUpTRM1Y"
      },
      "source": [
        "# ConvLayer creates a sequence of convolutional (ni to nf), ReLU (if use_activ) and norm_type layers\n",
        "def block(ni, nf): return ConvLayer(ni, nf, stride=2, ndim=1, ks=5)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBVw_3JARNqZ"
      },
      "source": [
        "def get_model():\n",
        "    return nn.Sequential(\n",
        "        block(20, 32), #how to handle this\n",
        "        block(32, 64),\n",
        "        block(64, 128),\n",
        "        block(128, 256),\n",
        "        nn.AdaptiveAvgPool1d(1),\n",
        "        Flatten(),\n",
        "        nn.Linear(256, 58)) "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOh92tvgRQt8"
      },
      "source": [
        "# metric\n",
        "#precision = Precision(average='weighted') \n",
        "# Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
        "# create learn object\n",
        "\n",
        "#learn = Learner(dls, get_model(), loss_func=nn.CrossEntropyLoss(), metrics=accuracy) # switched metric from accuracy to precision for assessing dataset balance"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgF09XkmVsRn"
      },
      "source": [
        "# try with cnn learner instead\n",
        "#learn = cnn_learner(dls, get_model(), loss_func=nn.CrossEntropyLoss(), pretrained = False, metrics = accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Riq7JkzWRU-F"
      },
      "source": [
        "#learn.summary()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWIj7EZZnGWJ"
      },
      "source": [
        "# Architechture for a 1D ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZGuFLmFnE9Y"
      },
      "source": [
        "import torchvision.models as models\n",
        "resnet18 = models.resnet18()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ruonptT32Ol"
      },
      "source": [
        "class ConvLayer(nn.Sequential):\n",
        "    \"Create a sequence of convolutional (`ni` to `nf`), ReLU (if `use_activ`) and `norm_type` layers.\"\n",
        "    @delegates(nn.Conv2d)\n",
        "    def __init__(self, ni, nf, ks=3, stride=1, padding=None, bias=None, ndim=2, norm_type=NormType.Batch, bn_1st=True,\n",
        "                 act_cls=defaults.activation, transpose=False, init='auto', xtra=None, bias_std=0.01, **kwargs):\n",
        "        if padding is None: padding = ((ks-1)//2 if not transpose else 0)\n",
        "        bn = norm_type in (NormType.Batch, NormType.BatchZero)\n",
        "        inn = norm_type in (NormType.Instance, NormType.InstanceZero)\n",
        "        if bias is None: bias = not (bn or inn)\n",
        "        conv_func = _conv_func(ndim, transpose=transpose)\n",
        "        conv = conv_func(ni, nf, kernel_size=ks, bias=bias, stride=stride, padding=padding, **kwargs)\n",
        "        act = None if act_cls is None else act_cls()\n",
        "        init_linear(conv, act, init=init, bias_std=bias_std)\n",
        "        if   norm_type==NormType.Weight:   conv = weight_norm(conv)\n",
        "        elif norm_type==NormType.Spectral: conv = spectral_norm(conv)\n",
        "        layers = [conv]\n",
        "        act_bn = []\n",
        "        if act is not None: act_bn.append(act)\n",
        "        if bn: act_bn.append(BatchNorm(nf, norm_type=norm_type, ndim=ndim))\n",
        "        if inn: act_bn.append(InstanceNorm(nf, norm_type=norm_type, ndim=ndim))\n",
        "        if bn_1st: act_bn.reverse()\n",
        "        layers += act_bn\n",
        "        if xtra: layers.append(xtra)\n",
        "        super().__init__(*layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16s7WOmy3qyD"
      },
      "source": [
        "# https://github.com/fastai/fastai/blob/08a639548fd82ff22b7a72db9519f82b176511d7/fastai/layers.py#L461\n",
        "class ResBlock(Module):\n",
        "    \"Resnet block from `ni` to `nh` with `stride`\"\n",
        "    @delegates(ConvLayer.__init__)\n",
        "    def __init__(self, expansion, ni, nf, stride=1, groups=1, reduction=None, nh1=None, nh2=None, dw=False, g2=1,\n",
        "                 sa=False, sym=False, norm_type=NormType.Batch, act_cls=defaults.activation, ndim=2, ks=3,\n",
        "                 pool=AvgPool, pool_first=True, **kwargs):\n",
        "        norm2 = (NormType.BatchZero if norm_type==NormType.Batch else\n",
        "                 NormType.InstanceZero if norm_type==NormType.Instance else norm_type)\n",
        "        if nh2 is None: nh2 = nf\n",
        "        if nh1 is None: nh1 = nh2\n",
        "        nf,ni = nf*expansion,ni*expansion\n",
        "        k0 = dict(norm_type=norm_type, act_cls=act_cls, ndim=ndim, **kwargs)\n",
        "        k1 = dict(norm_type=norm2, act_cls=None, ndim=ndim, **kwargs)\n",
        "        convpath  = [ConvLayer(ni,  nh2, ks, stride=stride, groups=ni if dw else groups, **k0),\n",
        "                     ConvLayer(nh2,  nf, ks, groups=g2, **k1)\n",
        "        ] if expansion == 1 else [\n",
        "                     ConvLayer(ni,  nh1, 1, **k0),\n",
        "                     ConvLayer(nh1, nh2, ks, stride=stride, groups=nh1 if dw else groups, **k0),\n",
        "                     ConvLayer(nh2,  nf, 1, groups=g2, **k1)]\n",
        "        if reduction: convpath.append(SEModule(nf, reduction=reduction, act_cls=act_cls))\n",
        "        if sa: convpath.append(SimpleSelfAttention(nf,ks=1,sym=sym))\n",
        "        self.convpath = nn.Sequential(*convpath)\n",
        "        idpath = []\n",
        "        if ni!=nf: idpath.append(ConvLayer(ni, nf, 1, act_cls=None, ndim=ndim, **kwargs))\n",
        "        if stride!=1: idpath.insert((1,0)[pool_first], pool(stride, ndim=ndim, ceil_mode=True))\n",
        "        self.idpath = nn.Sequential(*idpath)\n",
        "        self.act = defaults.activation(inplace=True) if act_cls is defaults.activation else act_cls()\n",
        "\n",
        "    def forward(self, x): return self.act(self.convpath(x) + self.idpath(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JutmnTDH9lmc"
      },
      "source": [
        "the following parts are from the book"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j5tlY6J9zGo",
        "outputId": "c163f14b-3de9-4467-9762-9c129cae100a"
      },
      "source": [
        "def _resnet_stem(*sizes): \n",
        "    return [\n",
        "        ConvLayer(sizes[i], sizes[i+1], 3, stride = 2 if i==0 else 1) for i in range(len(sizes)-1)\n",
        "    ] + [nn.MaxPool2d(kernel_size=3, stride=2, padding=1)]\n",
        "\n",
        "_resnet_stem(3,32,32,64)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ConvLayer(\n",
              "   (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   (2): ReLU()\n",
              " ), ConvLayer(\n",
              "   (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   (2): ReLU()\n",
              " ), ConvLayer(\n",
              "   (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   (2): ReLU()\n",
              " ), MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRbchCws9lIN"
      },
      "source": [
        "class ResNet(nn.Sequential):\n",
        "    def __init__(self, n_out, layers, expansion=1):\n",
        "        stem = _resnet_stem(3,32,32,64)\n",
        "        self.block_szs = [64, 64, 128, 256, 512]\n",
        "        for i in range(1,5): self.block_szs[i] *= expansion \n",
        "        blocks = [self._make_layer(*o) for o in enumerate(layers)] \n",
        "        super().__init__(*stem, *blocks,\n",
        "                        nn.AdaptiveAvgPool2d(1), Flatten(),\n",
        "                        nn.Linear(self.block_szs[-1], n_out))\n",
        "\n",
        "    def _make_layer(self, idx, n_layers): \n",
        "        stride = 1 if idx==0 else 2\n",
        "        ch_in,ch_out = self.block_szs[idx:idx+2] \n",
        "        return nn.Sequential(*[\n",
        "            ResBlock(ch_in if i==0 else ch_out, ch_out, stride if i==0 else 1)\n",
        "            for i in range(n_layers) \n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XALWLkBe-ooc"
      },
      "source": [
        "# this would be a ResNet18\n",
        "rn = ResNet(dls.c, [2,2,2,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrFpfhh9KDtY"
      },
      "source": [
        "# Training the 1D CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7AqO-LCRVbi"
      },
      "source": [
        "#learn.lr_find() # choose an adequate lr"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLkvmonACaI"
      },
      "source": [
        "#from fastai.callbacks import SaveModelCallback"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZQh0fvERV53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "415745f3-3927-4ba9-c956-36841b9952e3"
      },
      "source": [
        "# fit and train \n",
        "epochs=1\n",
        "lr=0.1\n",
        "learn = learn.fit_one_cycle(epochs, lr) #callbacks=[SaveModelCallback(learn, every='epoch',  monitor='accuracy', name='saved_1D_net')]) # make training more stable with fit_one_cycle"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.078036</td>\n",
              "      <td>0.079609</td>\n",
              "      <td>0.979353</td>\n",
              "      <td>12:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoWjtgH0boK0",
        "outputId": "47c607e4-ca13-41ce-95dd-11077034d576"
      },
      "source": [
        "#len(dls.train_ds)\n",
        "#type(learn) # it looks like after .fit the resulting learn object is of type None for some reason. \n",
        "# i think i have to pass a parameter when creating the learner so that some stats are saved to later build the confusion matrix\n",
        "#learn.dls\n",
        "learn.model"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): ConvLayer(\n",
              "    (0): Conv1d(20, 32, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (1): ConvLayer(\n",
              "    (0): Conv1d(32, 64, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (2): ConvLayer(\n",
              "    (0): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (3): ConvLayer(\n",
              "    (0): Conv1d(128, 256, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (4): AdaptiveAvgPool1d(output_size=1)\n",
              "  (5): Flatten(full=False)\n",
              "  (6): Linear(in_features=256, out_features=58, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_sLckAXPzbX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "ce9a1d72-2341-4cfa-c0fc-e05240e89f10"
      },
      "source": [
        "# confusion matrix\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "#interp.plot_confusion_matrix(figsize=(12,12), dpi=60)\n",
        "interp.most_confused(min_val=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='346' class='' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      92.27% [346/375 02:22<00:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "790lXw9baKRc"
      },
      "source": [
        "# Saving the 1D CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDuZZNUxaHAV"
      },
      "source": [
        "# save the architecture and the parameters\n",
        "learn.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tokZOszxaTDT"
      },
      "source": [
        "# check that the file exists\n",
        "path = Path()\n",
        "path.ls(file_exts='.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCx0vtzwaX0E"
      },
      "source": [
        "# load the model not for training but for making predictions (inference)\n",
        "learn_inf = load_learner(path/'export.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUxQmrbhalet"
      },
      "source": [
        "# make prediction\n",
        "learn_inf.predict('images/grizzly.jpg') # image as example\n",
        "'''returned three things: the predicted category in the same format you originally provided \n",
        "(in this case, that’s a string), the index of the predicted category, and the probabilities of each category\n",
        "The last two are based on the order of categories in the vocab of the DataLoaders '''\n",
        "# check vocab\n",
        "learn_inf.dls.vocab\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}